# Prática
```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

Neste capítulo será aplicaremos os conceitos vistos de ML e R para ....

# Classificação em dados simples

```{r}
# 1. Gerar dados sintéticos para duas classes
# O modelo será: y = -2 * x + 5 (com algum ruído)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 2, sd = 1),
  y = -2 * x + 5 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 6 + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```


```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```






```{r}
# 2. Treinar um modelo de regressão logística
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```


```{r}
# 4. Treinar o modelo de regressão logística nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previsões nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previsões nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classificação
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decisão é onde a probabilidade é 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classificação
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classificação Linear com Regressão Logística",
    subtitle = "A reta pontilhada é a fronteira de decisão do modelo",
    x = "Variável X",
    y = "Variável Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# 8. Calcular a matriz de confusão

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

```{r}

# 1. Definir o modelo de árvore de decisão (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(classe ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train_simulado)

# 4. Fazer previsões
tree_pred <- predict(tree_fit, new_data = test_simulado) %>%
  bind_cols(test_simulado)

# 5. Gerar a matriz de confusão
conf_mat(tree_pred, truth = classe, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a árvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))

```

```{r}
# 4. Fazer previsões nos dados de TREINO
tree_pred_train <- predict(tree_fit, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Gerar a matriz de confusão para os dados de TREINO
conf_mat(tree_pred_train, truth = classe, estimate = .pred_class)
```



```{r}
#| echo: true
# 1. Criar uma grade de pontos para o plano 2D (x e y)
# Definimos os limites da grade com base nos valores mínimos e máximos dos dados
grid <- expand.grid(
  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),
  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)
)

# 2. Fazer as previsões para cada ponto na grade usando o modelo de árvore
grid_preds_tree <- predict(tree_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# 3. Plotar as fronteiras de decisão e os dados originais
ggplot() +
  # Camada para as fronteiras de decisão
  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +
  # Adicionando rótulos e título
  labs(
    title = "Fronteiras de Decisão da Árvore de Decisão",
    subtitle = "Regiões de previsão do modelo de árvore",
    x = "Variável X",
    y = "Variável Y",
    fill = "Classe Prevista",
    color = "Classe Real"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```





(colocar um exemplo em 3D tb ?)

Exemplo de dados se cruzando:

```{r}
# 1. Gerar dados sintéticos para duas classes
# O modelo será: y = -2 * x + 5 (com algum ruído)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 16 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = 2 * x + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```


```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```






```{r}
# 2. Treinar um modelo de regressão logística
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```


```{r}
# 4. Treinar o modelo de regressão logística nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previsões nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previsões nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classificação
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decisão é onde a probabilidade é 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classificação
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classificação Linear com Regressão Logística",
    subtitle = "A reta pontilhada é a fronteira de decisão do modelo",
    x = "Variável X",
    y = "Variável Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# 8. Calcular a matriz de confusão

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```

Vamos ver algumas métricas, como acurácia, precisão, recall e F1-score.

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

Ou em uma tabela:

```{r}

```


```{r}

# 1. Definir o modelo de árvore de decisão (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(classe ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train_simulado)

# 4. Fazer previsões
tree_pred <- predict(tree_fit, new_data = test_simulado) %>%
  bind_cols(test_simulado)

# 5. Gerar a matriz de confusão
conf_mat(tree_pred, truth = classe, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a árvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))

```

```{r}
# 4. Fazer previsões nos dados de TREINO
tree_pred_train <- predict(tree_fit, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Gerar a matriz de confusão para os dados de TREINO
conf_mat(tree_pred_train, truth = classe, estimate = .pred_class)
```

```{r}
accuracy(tree_pred, truth = classe, estimate = .pred_class)

precision(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

recall(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")
```




```{r}
#| echo: true
# 1. Criar uma grade de pontos para o plano 2D (x e y)
# Definimos os limites da grade com base nos valores mínimos e máximos dos dados
grid <- expand.grid(
  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),
  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)
)

# 2. Fazer as previsões para cada ponto na grade usando o modelo de árvore
grid_preds_tree <- predict(tree_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# 3. Plotar as fronteiras de decisão e os dados originais
ggplot() +
  # Camada para as fronteiras de decisão
  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +
  # Adicionando rótulos e título
  labs(
    title = "Fronteiras de Decisão da Árvore de Decisão",
    subtitle = "Regiões de previsão do modelo de árvore",
    x = "Variável X",
    y = "Variável Y",
    fill = "Classe Prevista",
    color = "Classe Real"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

(ver o Statquest)


## Classificação: Pinguins do arquipélago Palmer

### **Conheça os pinguins** 🐧

![Obra de \@allison_horst.](images/clipboard-3055016893.png)

Os `palmerpenguins`dados contêm medições de tamanho de três espécies de pinguins observadas em três ilhas no Arquipélago Palmer, na Antártida.

Esses dados foram coletados entre 2007 e 2009 pela Dra. Kristen Gorman com o Programa de Pesquisa Ecológica de Longo Prazo da Estação Palmer , parte da Rede de Pesquisa Ecológica de Longo Prazo dos EUA . Os dados foram importados diretamente do Portal de Dados da Iniciativa de Dados Ambientais (EDI) e estão disponíveis para uso sob licença CC0 (“Sem Direitos Reservados”), de acordo com a Política de Dados da Estação Palmer.

Podemos acessar esses dados instalando a versão lançada do palmerpenguins do CRAN com:

```{r}
library(palmerpenguins)
glimpse(penguins)

```

![](images/clipboard-1302732821.png){fig-align="center" width="445"}

### Usando head()

```{r}
#|echo: true
```

Usar `head()` pode ser interessante para ter um primeiro olhar para os dados:

```{r}
head(penguins)

```

### Usando arrange()

`arrange()` organiza nossos dados em ordem *crescente*, partindo do menor valor da variável de interesse até o maior (ou em caso da variável ver qualitativa, será apresentado em ordem alfabética).

```{r}
penguins %>%
  arrange(bill_length_mm) %>%
  head()
```

### Criando um subconjunto com `subset()`

### Aplicação de um modelo de classificação

```{r}
# Carregando os pacotes
library(tidymodels)

# Criar um split treino/teste
set.seed(123)
split <- initial_split(penguins, prop = 0.7, strata = species)
train <- training(split)
test <- testing(split)

# Definir o modelo (regressão logística multinomial)
modelo <- multinom_reg() %>%
  set_engine("nnet") %>%
  set_mode("classification")

# Criar o workflow
workflow <- workflow() %>%
  add_model(modelo) %>%
  add_formula(species ~ .)

# Ajustar o modelo
ajustado <- fit(workflow, data = train)

# Previsão e avaliação
pred <- predict(ajustado, new_data = test) %>%
  bind_cols(test)

# Métricas de desempenho
metrics(pred, truth = species, estimate = .pred_class)

# Matriz de confusão
conf_mat(pred, truth = species, estimate = .pred_class)

```

```{r}
# Exemplo com Árvore de Decisão (mais visual para iniciantes)

# 1. Definir o modelo de árvore de decisão (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(species ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train)

# 4. Fazer previsões
tree_pred <- predict(tree_fit, new_data = test) %>%
  bind_cols(test)

# 5. Gerar a matriz de confusão
conf_mat(tree_pred, truth = species, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a árvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))
```




