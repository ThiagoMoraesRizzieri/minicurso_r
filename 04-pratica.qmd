# Pr√°tica
```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

Neste cap√≠tulo ser√° aplicaremos os conceitos vistos de ML e R para ....

# Classifica√ß√£o em dados simples

```{r}
# 1. Gerar dados sint√©ticos para duas classes
# O modelo ser√°: y = -2 * x + 5 (com algum ru√≠do)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 2, sd = 1),
  y = -2 * x + 5 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 6 + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```


```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```






```{r}
# 2. Treinar um modelo de regress√£o log√≠stica
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```


```{r}
# 4. Treinar o modelo de regress√£o log√≠stica nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previs√µes nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previs√µes nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classifica√ß√£o
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decis√£o √© onde a probabilidade √© 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classifica√ß√£o
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classifica√ß√£o Linear com Regress√£o Log√≠stica",
    subtitle = "A reta pontilhada √© a fronteira de decis√£o do modelo",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# 8. Calcular a matriz de confus√£o

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

```{r}

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(classe ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train_simulado)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test_simulado) %>%
  bind_cols(test_simulado)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = classe, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))

```

```{r}
# 4. Fazer previs√µes nos dados de TREINO
tree_pred_train <- predict(tree_fit, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Gerar a matriz de confus√£o para os dados de TREINO
conf_mat(tree_pred_train, truth = classe, estimate = .pred_class)
```



```{r}
#| echo: true
# 1. Criar uma grade de pontos para o plano 2D (x e y)
# Definimos os limites da grade com base nos valores m√≠nimos e m√°ximos dos dados
grid <- expand.grid(
  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),
  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)
)

# 2. Fazer as previs√µes para cada ponto na grade usando o modelo de √°rvore
grid_preds_tree <- predict(tree_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# 3. Plotar as fronteiras de decis√£o e os dados originais
ggplot() +
  # Camada para as fronteiras de decis√£o
  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +
  # Adicionando r√≥tulos e t√≠tulo
  labs(
    title = "Fronteiras de Decis√£o da √Årvore de Decis√£o",
    subtitle = "Regi√µes de previs√£o do modelo de √°rvore",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    fill = "Classe Prevista",
    color = "Classe Real"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```





(colocar um exemplo em 3D tb ?)

Exemplo de dados se cruzando:

```{r}
# 1. Gerar dados sint√©ticos para duas classes
# O modelo ser√°: y = -2 * x + 5 (com algum ru√≠do)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 16 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = 2 * x + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```


```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```






```{r}
# 2. Treinar um modelo de regress√£o log√≠stica
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```


```{r}
# 4. Treinar o modelo de regress√£o log√≠stica nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previs√µes nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previs√µes nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classifica√ß√£o
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decis√£o √© onde a probabilidade √© 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classifica√ß√£o
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classifica√ß√£o Linear com Regress√£o Log√≠stica",
    subtitle = "A reta pontilhada √© a fronteira de decis√£o do modelo",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# 8. Calcular a matriz de confus√£o

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```

Vamos ver algumas m√©tricas, como acur√°cia, precis√£o, recall e F1-score.

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

Ou em uma tabela:

```{r}

```


```{r}

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(classe ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train_simulado)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test_simulado) %>%
  bind_cols(test_simulado)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = classe, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))

```

```{r}
# 4. Fazer previs√µes nos dados de TREINO
tree_pred_train <- predict(tree_fit, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Gerar a matriz de confus√£o para os dados de TREINO
conf_mat(tree_pred_train, truth = classe, estimate = .pred_class)
```

```{r}
accuracy(tree_pred, truth = classe, estimate = .pred_class)

precision(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

recall(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")
```




```{r}
#| echo: true
# 1. Criar uma grade de pontos para o plano 2D (x e y)
# Definimos os limites da grade com base nos valores m√≠nimos e m√°ximos dos dados
grid <- expand.grid(
  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),
  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)
)

# 2. Fazer as previs√µes para cada ponto na grade usando o modelo de √°rvore
grid_preds_tree <- predict(tree_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# 3. Plotar as fronteiras de decis√£o e os dados originais
ggplot() +
  # Camada para as fronteiras de decis√£o
  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +
  # Adicionando r√≥tulos e t√≠tulo
  labs(
    title = "Fronteiras de Decis√£o da √Årvore de Decis√£o",
    subtitle = "Regi√µes de previs√£o do modelo de √°rvore",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    fill = "Classe Prevista",
    color = "Classe Real"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

(ver o Statquest)


## Classifica√ß√£o: Pinguins do arquip√©lago Palmer

### **Conhe√ßa os pinguins** üêß

![Obra de¬†\@allison_horst.](images/clipboard-3055016893.png)

Os `palmerpenguins`dados cont√™m medi√ß√µes de tamanho de tr√™s esp√©cies de pinguins observadas em tr√™s ilhas no Arquip√©lago Palmer, na Ant√°rtida.

Esses dados foram coletados entre 2007 e 2009 pela Dra. Kristen Gorman com o Programa de Pesquisa Ecol√≥gica de Longo Prazo da Esta√ß√£o Palmer , parte da Rede de Pesquisa Ecol√≥gica de Longo Prazo dos EUA . Os dados foram importados diretamente do Portal de Dados da Iniciativa de Dados Ambientais (EDI) e est√£o dispon√≠veis para uso sob licen√ßa CC0 (‚ÄúSem Direitos Reservados‚Äù), de acordo com a Pol√≠tica de Dados da Esta√ß√£o Palmer.

Podemos acessar esses dados instalando a vers√£o lan√ßada do palmerpenguins do CRAN com:

```{r}
library(palmerpenguins)
glimpse(penguins)

```

![](images/clipboard-1302732821.png){fig-align="center" width="445"}

### Usando head()

```{r}
#|echo: true
```

Usar¬†`head()`¬†pode ser interessante para ter um primeiro olhar para os dados:

```{r}
head(penguins)

```

### Usando arrange()

`arrange()`¬†organiza nossos dados em ordem *crescente*, partindo do menor valor da vari√°vel de interesse at√© o maior (ou em caso da vari√°vel ver qualitativa, ser√° apresentado em ordem alfab√©tica).

```{r}
penguins %>%
  arrange(bill_length_mm) %>%
  head()
```

### Criando um subconjunto com `subset()`

### Aplica√ß√£o de um modelo de classifica√ß√£o

```{r}
# Carregando os pacotes
library(tidymodels)

# Criar um split treino/teste
set.seed(123)
split <- initial_split(penguins, prop = 0.7, strata = species)
train <- training(split)
test <- testing(split)

# Definir o modelo (regress√£o log√≠stica multinomial)
modelo <- multinom_reg() %>%
  set_engine("nnet") %>%
  set_mode("classification")

# Criar o workflow
workflow <- workflow() %>%
  add_model(modelo) %>%
  add_formula(species ~ .)

# Ajustar o modelo
ajustado <- fit(workflow, data = train)

# Previs√£o e avalia√ß√£o
pred <- predict(ajustado, new_data = test) %>%
  bind_cols(test)

# M√©tricas de desempenho
metrics(pred, truth = species, estimate = .pred_class)

# Matriz de confus√£o
conf_mat(pred, truth = species, estimate = .pred_class)

```

```{r}
# Exemplo com √Årvore de Decis√£o (mais visual para iniciantes)

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(species ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test) %>%
  bind_cols(test)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = species, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))
```




