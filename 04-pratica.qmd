# Modelo de Classifica√ß√£o

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

Neste cap√≠tulo, vamos aplicar os conceitos de Machine Learning (ML) em R usando o ecossistema `tidymodels`. Come√ßaremos com dados simples e sint√©ticos para entender a l√≥gica por tr√°s dos modelos de classifica√ß√£o, e depois aplicaremos esses mesmos conceitos a um conjunto de dados mais realista.

## Classifica√ß√£o em dados simples

Vamos come√ßar gerando um conjunto de dados bidimensional simples que pode ser separado por uma linha reta. Isso nos permitir√° visualizar claramente como um modelo de regress√£o log√≠stica funciona.

```{r}
# 1. Gerar dados sint√©ticos para duas classes

# Os dados da classe A s√£o gerados por: y = -2 * x + 5 (com algum ru√≠do)
# Os dados da classe B s√£o gerados por: y = -2 * x + 6 (com algum ru√≠do)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 2, sd = 1),
  y = -2 * x + 5 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 6 + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

Para entender melhor os dados que acabamos de criar, vamos visualiz√°-los. O gr√°fico a seguir mostra a distribui√ß√£o dos pontos no plano cartesiano. Podemos ver que as duas classes formam dois "aglomerados" distintos.

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```

Nesse pr√≥ximo gr√°fico, podemos observar cada uma das classes sendo representadas por uma cor. De fato, a diferen√ßa de aglomerados visto no gr√°fico anterior sugere a diferen√ßa entre os dois grupos.

```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```

### Preparando os Dados para o Modelo

Antes de treinar o modelo, √© uma pr√°tica essencial dividir o nosso conjunto de dados em dois subconjuntos: **treino** e **teste**.

-   O conjunto de **treino** √© usado para "ensinar" o modelo a identificar padr√µes.

-   O conjunto de **teste** √© usado para avaliar o desempenho do modelo em dados que ele **nunca viu antes**, garantindo uma avalia√ß√£o mais realista.

```{r}
# 2. Treinar um modelo de regress√£o log√≠stica
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```

### Treinando e Avaliando o Modelo de Regress√£o Log√≠stica

Agora, vamos usar a biblioteca `tidymodels` para construir, treinar e avaliar o nosso modelo de **Regress√£o Log√≠stica**, que √© um algoritmo de classifica√ß√£o linear.

```{r}
# 4. Treinar o modelo de regress√£o log√≠stica nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previs√µes nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

```

### Visualizando a Fronteira de Decis√£o

A grande vantagem de usar dados sint√©ticos √© que podemos visualizar a "fronteira de decis√£o" que o modelo encontrou para separar as duas classes. A **Regress√£o Log√≠stica** sempre encontrar√° uma linha reta para fazer essa separa√ß√£o.

```{r}
# 5. Fazer previs√µes nos dados de TESTE}
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classifica√ß√£o
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decis√£o √© onde a probabilidade √© 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classifica√ß√£o
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classifica√ß√£o Linear com Regress√£o Log√≠stica",
    subtitle = "A reta pontilhada √© a fronteira de decis√£o do modelo",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### Avaliando o Desempenho do Modelo

Uma das ferramentas mais importantes para avaliar um modelo de classifica√ß√£o √© a **Matriz de Confus√£o**. Ela mostra o qu√£o bem o modelo classificou as amostras, comparando as classes previstas com as classes reais.

-   **Verdadeiros Positivos (TP):** Predi√ß√µes corretas da classe positiva.

-   **Verdadeiros Negativos (TN):** Predi√ß√µes corretas da classe negativa.

-   **Falsos Positivos (FP):** Erro tipo I. Predi√ß√µes incorretas da classe positiva.

-   **Falsos Negativos (FN):** Erro tipo II. Predi√ß√µes incorretas da classe negativa.

```{r}
# 8. Calcular a matriz de confus√£o

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao_teste <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao_teste

```

```{r}
autoplot(matriz_confusao_teste, type = "heatmap") +
  labs(title = "Matriz de Confus√£o (Dados de Teste)")
```

Al√©m da matriz de confus√£o, podemos usar outras m√©tricas para uma avalia√ß√£o mais completa:

-   **Acur√°cia (Accuracy):** Propor√ß√£o de predi√ß√µes corretas em rela√ß√£o ao total.

-   **Precis√£o (Precision):** A propor√ß√£o de predi√ß√µes positivas que estavam corretas.

-   **Recall (Sensibilidade):** A propor√ß√£o de casos positivos reais que foram identificados corretamente.

-   **F1-Score:** M√©dia harm√¥nica de Precis√£o e Recall.

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

## 2. Classifica√ß√£o com Dados N√£o-Lineares (√Årvore de Decis√£o)

E se os dados n√£o puderem ser separados por uma linha reta? Vamos gerar um novo conjunto de dados onde as classes se "cruzam" e testar a Regress√£o Log√≠stica novamente, para ent√£o compar√°-la com um modelo mais flex√≠vel: a **√Årvore de Decis√£o**.

### Gerando Dados N√£o-Lineares

```{r}
# 1. Gerar dados sint√©ticos para duas classes

set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 16 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = 2 * x + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

Vamos plotar esses novos dados.

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```

Agora colorindo cada uma das classes.

```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```

Perceba que as classes A e B n√£o s√£o separ√°veis por uma √∫nica linha reta.

### Regress√£o Log√≠stica em Dados N√£o-Lineares

Agora, vamos tentar aplicar o mesmo modelo de Regress√£o Log√≠stica. A fronteira de decis√£o ser√° uma linha reta, mas veremos que ela n√£o conseguir√° separar bem as classes.

```{r}
# 2. Treinar um modelo de regress√£o log√≠stica
dados_simulados$classe <- as.factor(dados_simulados$classe)

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```

```{r}
# 4. Treinar o modelo de regress√£o log√≠stica nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previs√µes nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previs√µes nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classifica√ß√£o
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decis√£o √© onde a probabilidade √© 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classifica√ß√£o
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classifica√ß√£o Linear com Regress√£o Log√≠stica",
    subtitle = "A reta pontilhada √© a fronteira de decis√£o do modelo",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

```{r}
# 8. Calcular a matriz de confus√£o

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```

Vamos ver algumas m√©tricas, como acur√°cia, precis√£o, recall e F1-score.

```{r}
accuracy(preds_test, truth = classe, estimate = .pred_class)

precision(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

recall(preds_test, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(preds_test, truth = classe, estimate = .pred_class, event_level = "second")
```

Como esperado, a matriz de confus√£o e as m√©tricas de desempenho mostram que o modelo teve dificuldade em separar os dados.

### √Årvore de Decis√£o em Dados N√£o-Lineares

Agora, vamos usar uma **√Årvore de Decis√£o**, um modelo de classifica√ß√£o que n√£o √© restrito a fronteiras lineares.

```{r}

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(classe ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train_simulado)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test_simulado) %>%
  bind_cols(test_simulado)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = classe, estimate = .pred_class)

```

```{r}
# 4. Fazer previs√µes nos dados de TREINO
tree_pred_train <- predict(tree_fit, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Gerar a matriz de confus√£o para os dados de TREINO
conf_mat(tree_pred_train, truth = classe, estimate = .pred_class)
```

```{r}
accuracy(tree_pred, truth = classe, estimate = .pred_class)

precision(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

recall(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")

f_meas(tree_pred, truth = classe, estimate = .pred_class, event_level = "second")
```

Perceba que a acur√°cia do modelo de √Årvore de Decis√£o foi significativamente maior! Isso acontece porque ele pode criar fronteiras de decis√£o complexas, que n√£o s√£o apenas linhas retas.

### Visualizando as Fronteiras de Decis√£o da √Årvore

Para entender como a √Årvore de Decis√£o classificou os dados, vamos plotar as regi√µes de decis√£o. O resultado √© uma √°rea segmentada em ret√¢ngulos, onde cada ret√¢ngulo representa a previs√£o de uma classe.

```{r}
#| echo: true
# 1. Criar uma grade de pontos para o plano 2D (x e y)
# Definimos os limites da grade com base nos valores m√≠nimos e m√°ximos dos dados
grid <- expand.grid(
  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),
  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)
)

# 2. Fazer as previs√µes para cada ponto na grade usando o modelo de √°rvore
grid_preds_tree <- predict(tree_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# 3. Plotar as fronteiras de decis√£o e os dados originais
ggplot() +
  # Camada para as fronteiras de decis√£o
  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +
  # Adicionando r√≥tulos e t√≠tulo
  labs(
    title = "Fronteiras de Decis√£o da √Årvore de Decis√£o",
    subtitle = "Regi√µes de previs√£o do modelo de √°rvore",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    fill = "Classe Prevista",
    color = "Classe Real"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

Podemos visualizar a √°rvore com as perguntas feitas.

```{r}
# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))
```

## Classifica√ß√£o: Pinguins do arquip√©lago Palmer

Agora que voc√™ entendeu os conceitos b√°sicos, vamos aplicar o mesmo fluxo de trabalho em um conjunto de dados real: as medi√ß√µes dos pinguins da Ant√°rtida. Nosso objetivo ser√° classificar a **esp√©cie** do pinguim com base em suas caracter√≠sticas f√≠sicas.

### **Conhe√ßa os pinguins** üêß

![Obra de¬†\@allison_horst.](images/clipboard-3055016893.png)

Os `palmerpenguins`dados cont√™m medi√ß√µes de tamanho de tr√™s esp√©cies de pinguins observadas em tr√™s ilhas no Arquip√©lago Palmer, na Ant√°rtida.

Esses dados foram coletados entre 2007 e 2009 pela Dra. Kristen Gorman com o Programa de Pesquisa Ecol√≥gica de Longo Prazo da Esta√ß√£o Palmer , parte da Rede de Pesquisa Ecol√≥gica de Longo Prazo dos EUA . Os dados foram importados diretamente do Portal de Dados da Iniciativa de Dados Ambientais (EDI) e est√£o dispon√≠veis para uso sob licen√ßa CC0 (‚ÄúSem Direitos Reservados‚Äù), de acordo com a Pol√≠tica de Dados da Esta√ß√£o Palmer.

Podemos acessar esses dados instalando a vers√£o lan√ßada do palmerpenguins do CRAN com:

```{r}
library(palmerpenguins)
glimpse(penguins)

```

![](images/clipboard-786638237.png){fig-align="center"}

Nosso objetivo ser√° classificar a **esp√©cie** do pinguim com base em suas caracter√≠sticas f√≠sicas.

### Preparando os Dados

Antes de modelar, precisamos tratar os valores ausentes (`NA`) e dividir os dados.

### Aplica√ß√£o de um modelo de classifica√ß√£o

```{r}
# Criar um split treino/teste
set.seed(123)
split <- initial_split(penguins, prop = 0.7, strata = species)
train <- training(split)
test <- testing(split)
```

```{r}
dim(train)
dim(test)
```

### **Aplica√ß√£o de um modelo de classifica√ß√£o: Regress√£o Log√≠stica Multinomial**

Vamos agora aplicar a **regress√£o log√≠stica multinomial** aos dados dos pinguins. Este modelo √© uma extens√£o da regress√£o log√≠stica bin√°ria, que permite classificar dados em tr√™s ou mais categorias.

```{r}
#| echo: true
# 1. Definir o modelo de regress√£o log√≠stica multinomial
# O 'set_engine("nnet")' especifica o pacote que ser√° usado para o c√°lculo
modelo_multinomial <- multinom_reg() %>%
  set_engine("nnet") %>%
  set_mode("classification")

# 2. Criar o workflow (fluxo de trabalho)
# O 'add_formula(species ~ .)' diz ao modelo para usar todas as outras vari√°veis
# para prever a esp√©cie (species)
workflow_multinomial <- workflow() %>%
  add_model(modelo_multinomial) %>%
  add_formula(species ~ .)

# 3. Ajustar (treinar) o modelo com os dados de TREINO
# O 'fit()' executa o treinamento do modelo
ajustado_multinomial <- fit(workflow_multinomial, data = train)

# 4. Fazer previs√µes nos dados de TESTE
# O 'predict()' usa o modelo treinado para prever a esp√©cie nos dados de teste
pred_multinomial <- predict(ajustado_multinomial, new_data = test) %>%
  bind_cols(test)

# 5. Avaliar o desempenho com a Matriz de Confus√£o
# A 'conf_mat()' compara as previs√µes (.pred_class) com a realidade (species)
matriz_confusao_multinomial <- conf_mat(pred_multinomial, truth = species, estimate = .pred_class)
matriz_confusao_multinomial

```

A matriz de confus√£o acima mostra o desempenho do modelo em prever a esp√©cie de pinguim. Cada linha representa a esp√©cie real, e cada coluna representa a esp√©cie prevista. Os valores na diagonal mostram o n√∫mero de acertos do modelo para cada esp√©cie.

Para uma avalia√ß√£o mais completa, tamb√©m podemos verificar as principais m√©tricas de classifica√ß√£o.

```{r}
#| echo: true
# M√©tricas de desempenho
metrics(pred_multinomial, truth = species, estimate = .pred_class)
```

### Treinando e Avaliando o Modelo de √Årvore de Decis√£o

Vamos usar uma **√Årvore de Decis√£o** para este exemplo, pois ela √© intuitiva e a visualiza√ß√£o da √°rvore ajuda a entender o processo de tomada de decis√£o.

```{r}
# Exemplo com √Årvore de Decis√£o (mais visual para iniciantes)

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(species ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test) %>%
  bind_cols(test)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = species, estimate = .pred_class)


```

Voc√™ tamb√©m pode extrair as m√©tricas de desempenho:

```{r}
metrics(tree_pred, truth = species, estimate = .pred_class)
```

### Visualizando a √Årvore de Decis√£o

A beleza da √Årvore de Decis√£o √© que podemos visualizar o conjunto de regras que ela aprendeu. Cada n√≥ representa uma decis√£o baseada em uma vari√°vel (por exemplo, `flipper_length_mm`).

```{r}
# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))
```

A visualiza√ß√£o da √°rvore mostra o caminho que o modelo segue para classificar cada pinguim. Por exemplo, se o comprimento da nadadeira (`flipper_length_mm`) for maior ou igual a 207 mm e a profundidade do bico (`bill_depth_mm`) for maior ou igual a 17 mm, o pinguim ser√° classificado como `Chistrap`.

Este exemplo ilustra como modelos de classifica√ß√£o podem ser usados para resolver problemas pr√°ticos e como a visualiza√ß√£o pode ser uma ferramenta poderosa para interpretar os resultados.
