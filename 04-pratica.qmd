# Pr√°tica
```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

Neste cap√≠tulo ser√° aplicaremos os conceitos vistos de ML e R para ....

# Classifica√ß√£o em dados simples

```{r}
# 1. Gerar dados sint√©ticos para duas classes
# O modelo ser√°: y = -2 * x + 5 (com algum ru√≠do)
set.seed(42)
n_obs <- 1000

data_class_a <- tibble(
  x = rnorm(n_obs, mean = 2, sd = 1),
  y = -2 * x + 5 + rnorm(n_obs, mean = 0, sd = 1)
) %>%
  mutate(classe = "A")

data_class_b <- tibble(
  x = rnorm(n_obs, mean = 4, sd = 1),
  y = -2 * x + 6 + rnorm(n_obs, mean = 2, sd = 1)
) %>%
  mutate(classe = "B")

# Unir os dataframes e misturar
dados_simulados <- bind_rows(data_class_a, data_class_b) %>%
  sample_frac(1)

head(dados_simulados)
```

```{r}
ggplot(dados_simulados, aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7) 
```


```{r}
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) 
```






```{r}
# 2. Treinar um modelo de regress√£o log√≠stica
dados_simulados$classe <- as.factor(dados_simulados$classe)

modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
  

# 3. Dividir os dados em treino e teste
split_simulado <- initial_split(dados_simulados, prop = 0.7, strata = classe)
train_simulado <- training(split_simulado)
test_simulado <- testing(split_simulado)
```

```{r}
dim(train_simulado)
dim(test_simulado)
```


```{r}
# 4. Treinar o modelo de regress√£o log√≠stica nos dados de TREINO
modelo_logistico_simples <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification") %>%
  fit(classe ~ x + y, data = train_simulado)

# Fazer previs√µes nos dados de TREINO
preds_train <- predict(modelo_logistico_simples, new_data = train_simulado) %>%
  bind_cols(train_simulado)

# 5. Fazer previs√µes nos dados de TESTE
preds_test <- predict(modelo_logistico_simples, new_data = test_simulado) %>%
  bind_cols(test_simulado)


# 6. Extrair os coeficientes para a reta de classifica√ß√£o
intercept <- modelo_logistico_simples$fit$coefficients["(Intercept)"]
coef_x <- modelo_logistico_simples$fit$coefficients["x"]
coef_y <- modelo_logistico_simples$fit$coefficients["y"]

# A reta de decis√£o √© onde a probabilidade √© 0.5, ou seja, -intercept = coef_x*x + coef_y*y
# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)
slope <- -coef_x / coef_y
intercept_line <- -intercept / coef_y

# 7. Visualizar os dados e a reta de classifica√ß√£o
ggplot(dados_simulados, aes(x = x, y = y, color = classe)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_abline(intercept = intercept_line, slope = slope, linetype = "dashed", size = 1, color = "black") +
  labs(
    title = "Classifica√ß√£o Linear com Regress√£o Log√≠stica",
    subtitle = "A reta pontilhada √© a fronteira de decis√£o do modelo",
    x = "Vari√°vel X",
    y = "Vari√°vel Y",
    color = "Classe"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r}
# 8. Calcular a matriz de confus√£o

matriz_confusao <- conf_mat(preds_train, truth = classe, estimate = .pred_class)
matriz_confusao

matriz_confusao <- conf_mat(preds_test, truth = classe, estimate = .pred_class)
matriz_confusao

```

```{r}
autoplot(matriz_confusao, type = "heatmap")
```


(colocar um exemplo em 3D tb ?)






## Classifica√ß√£o: Pinguins do arquip√©lago Palmer

### **Conhe√ßa os pinguins** üêß

![Obra de¬†\@allison_horst.](images/clipboard-3055016893.png)

Os `palmerpenguins`dados cont√™m medi√ß√µes de tamanho de tr√™s esp√©cies de pinguins observadas em tr√™s ilhas no Arquip√©lago Palmer, na Ant√°rtida.

Esses dados foram coletados entre 2007 e 2009 pela Dra. Kristen Gorman com o Programa de Pesquisa Ecol√≥gica de Longo Prazo da Esta√ß√£o Palmer , parte da Rede de Pesquisa Ecol√≥gica de Longo Prazo dos EUA . Os dados foram importados diretamente do Portal de Dados da Iniciativa de Dados Ambientais (EDI) e est√£o dispon√≠veis para uso sob licen√ßa CC0 (‚ÄúSem Direitos Reservados‚Äù), de acordo com a Pol√≠tica de Dados da Esta√ß√£o Palmer.

Podemos acessar esses dados instalando a vers√£o lan√ßada do palmerpenguins do CRAN com:

```{r}
library(palmerpenguins)
glimpse(penguins)

```

![](images/clipboard-1302732821.png){fig-align="center" width="445"}

### Usando head()

```{r}
#|echo: true
```

Usar¬†`head()`¬†pode ser interessante para ter um primeiro olhar para os dados:

```{r}
head(penguins)

```

### Usando arrange()

`arrange()`¬†organiza nossos dados em ordem *crescente*, partindo do menor valor da vari√°vel de interesse at√© o maior (ou em caso da vari√°vel ver qualitativa, ser√° apresentado em ordem alfab√©tica).

```{r}
penguins %>%
  arrange(bill_length_mm) %>%
  head()
```

### Criando um subconjunto com `subset()`

### Aplica√ß√£o de um modelo de classifica√ß√£o

```{r}
# Carregando os pacotes
library(tidymodels)

# Criar um split treino/teste
set.seed(123)
split <- initial_split(penguins, prop = 0.7, strata = species)
train <- training(split)
test <- testing(split)

# Definir o modelo (regress√£o log√≠stica multinomial)
modelo <- multinom_reg() %>%
  set_engine("nnet") %>%
  set_mode("classification")

# Criar o workflow
workflow <- workflow() %>%
  add_model(modelo) %>%
  add_formula(species ~ .)

# Ajustar o modelo
ajustado <- fit(workflow, data = train)

# Previs√£o e avalia√ß√£o
pred <- predict(ajustado, new_data = test) %>%
  bind_cols(test)

# M√©tricas de desempenho
metrics(pred, truth = species, estimate = .pred_class)

# Matriz de confus√£o
conf_mat(pred, truth = species, estimate = .pred_class)

```

```{r}
# Exemplo com √Årvore de Decis√£o (mais visual para iniciantes)

# 1. Definir o modelo de √°rvore de decis√£o (rpart)
tree_model <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# 2. Criar o workflow
tree_workflow <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(species ~ .)

# 3. Ajustar (treinar) o modelo
tree_fit <- fit(tree_workflow, data = train)

# 4. Fazer previs√µes
tree_pred <- predict(tree_fit, new_data = test) %>%
  bind_cols(test)

# 5. Gerar a matriz de confus√£o
conf_mat(tree_pred, truth = species, estimate = .pred_class)

# O pacote rpart.plot ajuda a visualizar a √°rvore
# install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))
```



```{r}
penguins_completo <- penguins %>%
  drop_na()


# Realizando a PCA
# Usamos apenas as colunas num√©ricas que ser√£o usadas para a modelagem
pca_fit <- prcomp(penguins_completo %>% select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g),
                  scale = TRUE)

# Adicionando os componentes principais ao dataframe
penguins_pca <- penguins_completo %>%
  mutate(PC1 = pca_fit$x[,1], PC2 = pca_fit$x[,2])
```

```{r}
# Definindo o modelo de regress√£o log√≠stica
linear_model_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Criando o workflow e ajustando o modelo
linear_wf <- workflow() %>%
  add_formula(species ~ PC1 + PC2) %>% # Usamos apenas os 2 componentes principais
  add_model(linear_model_spec)

linear_fit <- fit(linear_wf, data = penguins_pca)
```

```{r}
# Criando uma grade de pontos para o plano 2D (PC1 e PC2)
grid <- expand.grid(
  PC1 = seq(min(penguins_pca$PC1) - 1, max(penguins_pca$PC1) + 1, length.out = 100),
  PC2 = seq(min(penguins_pca$PC2) - 1, max(penguins_pca$PC2) + 1, length.out = 100)
)

# Fazendo as previs√µes para cada ponto na grade
grid_preds <- predict(linear_fit, new_data = grid, type = "class") %>%
  bind_cols(grid)

# Plotando as fronteiras de decis√£o e os dados originais
ggplot() +
  # Camada para as fronteiras de decis√£o
  geom_raster(data = grid_preds, aes(x = PC1, y = PC2, fill = .pred_class), alpha = 0.5) +
  # Camada para os pontos de dados originais
  geom_point(data = penguins_pca, aes(x = PC1, y = PC2, color = species), size = 2) +
  # Adicionando r√≥tulos e t√≠tulo
  labs(
    title = "Fronteiras de Decis√£o do Modelo Linear (PCA + Regress√£o Log√≠stica)",
    x = "Componente Principal 1",
    y = "Componente Principal 2",
    fill = "Classe Prevista",
    color = "Esp√©cie Real"
  ) +
  theme_minimal()
```




