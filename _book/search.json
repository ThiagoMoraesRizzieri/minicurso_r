[
  {
    "objectID": "04-pratica.html",
    "href": "04-pratica.html",
    "title": "5  Modelo de Classificação",
    "section": "",
    "text": "5.1 Conceitos importantes ao aplicar um modelo de Aprendizado de Máquina\nNeste capítulo, vamos aplicar os conceitos de Machine Learning (ML) em R usando o ecossistema tidymodels. Começaremos com dados simples e sintéticos para entender a lógica por trás dos modelos de classificação, e depois aplicaremos esses mesmos conceitos a um conjunto de dados mais realista.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "04-pratica.html#conceitos-importantes-ao-aplicar-um-modelo-de-aprendizado-de-máquina",
    "href": "04-pratica.html#conceitos-importantes-ao-aplicar-um-modelo-de-aprendizado-de-máquina",
    "title": "5  Modelo de Classificação",
    "section": "",
    "text": "Sobreajuste (Overfitting) e Subajuste (Underfitting): O sobreajuste acontece quando o modelo “memoriza” os dados de treinamento em vez de aprender a generalizar os padrões, falhando em novos dados. O subajuste acontece quando o modelo é muito simples e não consegue capturar nem mesmo os padrões básicos nos dados.\nDados de treino e dados de teste: Para avaliar se o modelo está generalizando bem, a base de dados é dividida. O modelo é treinado com a maior parte dos dados (dados de treino) e depois é avaliado em uma porção que ele nunca viu antes (dados de teste).\nViés versus variância: O viés é o erro que o modelo comete por ser muito simples (subajuste). A variância, neste contexto, reflete a grande variação dos parâmetros estimados de um modelo a pequenas variações nos dados de treinamento (sobreajuste). Encontrar o equilíbrio entre os dois é crucial. Vale ressaltar que o termo “variância” geralmente reflete o sentido estatístico (uma medida de variação dos dados em relação à média dos dados).\nMétricas de avaliação: São usadas para medir o desempenho do modelo nos dados de teste. Dependendo do problema, podem ser usadas métricas como acurácia (a proporção de previsões corretas), precisão e revocação.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "04-pratica.html#como-funcionam-os-modelos-de-classificação",
    "href": "04-pratica.html#como-funcionam-os-modelos-de-classificação",
    "title": "5  Modelo de Classificação",
    "section": "5.2 Como funcionam os modelos de classificação?",
    "text": "5.2 Como funcionam os modelos de classificação?\nO objetivo de um modelo de classificação é prever a qual categoria (ou “classe”) uma observação pertence. Diferente da regressão, que prevê um valor numérico contínuo, a classificação trabalha com rótulos discretos, como A ou B, doente ou saudável ou espécies de pinguins, que estudamos no capítulo anterior.\nA ideia geral da modelagem é encontrar uma função matemática que use as características dos nossos dados (as variáveis x e y no nosso exemplo, ou as medidas do pinguim) para prever a classe. O processo de “treinamento” é exatamente onde o modelo “aprende” a melhor função para realizar essa tarefa.\nPara fazer isso de forma confiável, é crucial aplicar os conceitos de divisão de treino e teste, viés e variância e métricas de avaliação, que foram explicados no Capítulo 1. O objetivo é evitar o sobreajuste, garantindo que o modelo não apenas memorize os dados de treino, mas também seja capaz de generalizar e fazer boas previsões em dados novos.\nVeremos dois modelos de classificação neste minicurso.\n\n5.2.1 Modelo Logístico\nA Regressão Logística é um modelo de classificação que pertence à família dos Modelos Lineares Generalizados. Esses modelos “generalizam” a ideia da regressão linear para lidar com variáveis de resposta que não seguem uma distribuição normal ou que não são contínuas.\nA princípio, a regressão logística foi desenvolvida para problemas de duas classes (também conhecidos como classificação binária). Nesses casos, o objetivo é estimar a probabilidade (p) de um dado pertencer a uma das classes com base em suas características. Como a variável de resposta é binária (o evento acontece ou não), sua distribuição de probabilidade é de Bernoulli. Por não ser uma distribuição normal, ela requer um modelo linear generalizado, e a função de ligação canônica para esse caso é o modelo de Regressão Logística. Essa função de ligação, chamada logit, é a ponte matemática que transforma a regressão linear em uma probabilidade.\n\n\n\nObservemos que a função logística leva os valores reais para valores entre 0 e 1.\n\n\nApesar de ter a palavra “regressão” no nome, seu propósito é a classificação.\nO modelo funciona encontrando a melhor linha reta (ou um plano, em mais dimensões) que separa as classes. Ele não prevê a classe diretamente, mas sim a probabilidade de uma observação pertencer a uma determinada classe. Por exemplo, pode prever que um ponto tem 90% de chance de ser da Classe A e 10% de ser da Classe B.\nSe a probabilidade calculada for superior a 50%, o modelo classifica a observação em uma classe; caso contrário, na outra. Isso torna a fronteira de decisão (o lugar onde a probabilidade é exatamente 50%) uma linha reta, como veremos a seguir.\nEssa abordagem também pode ser estendida para problemas com múltiplas classes (três ou mais) através da Regressão Logística Multinomial, que irá criar segmentos de reta para separar as diferentes classes.\n\n\n5.2.2 Árvore de Decisão\nA Árvore de Decisão é um modelo de classificação mais intuitivo e poderoso, que não se limita a fronteiras de decisão lineares. Ela opera fazendo uma série de perguntas sobre os dados, uma após a outra. Cada “pergunta” (nó da árvore) divide o conjunto de dados em subconjuntos menores e mais homogêneos. Por exemplo, a primeira pergunta pode ser: “A massa corporal é maior que X gramas?”. Dependendo da resposta, o modelo faz uma nova pergunta para refinar a classificação.\nA “escolha” das perguntas é baseada em um critério de informação, calculado por medidas como a Entropia da Informação ou o Índice de Gini. A ideia é que cada nó seja o máximo em relação ao ganho de informação, ou seja, que a divisão seja a mais eficaz possível para separar as classes.\nO resultado é uma estrutura em forma de árvore, onde cada nó final (folha) representa uma classe. A Árvore de Decisão é excelente para capturar relações complexas e não-lineares, pois sua fronteira de decisão é uma série de segmentos de reta, e não apenas uma única linha.\nNo entanto, a natureza de dividir os dados em pequenos subconjuntos faz com que a árvore de decisão tenha uma inclinação para o sobreajuste. Para evitar que o modelo “memorize” os dados de treino, são necessárias técnicas de regularização como o poda (pruning) e a definição do número máximo de divisões. Modelos que utilizam múltiplas árvores, como a Floresta Aleatória, também surgiram como uma solução para essa limitação.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "04-pratica.html#classificação-em-dados-simples",
    "href": "04-pratica.html#classificação-em-dados-simples",
    "title": "5  Modelo de Classificação",
    "section": "5.3 Classificação em dados simples",
    "text": "5.3 Classificação em dados simples\nVamos começar gerando um conjunto de dados bidimensional simples que pode ser separado por uma linha reta. Isso nos permitirá visualizar claramente como um modelo de regressão logística funciona.\n\n# 1. Gerar dados sintéticos para duas classes\n\n# Os dados da classe A são gerados por: y = -2 * x + 5 (com algum ruído)\n# Os dados da classe B são gerados por: y = -2 * x + 6 (com algum ruído)\nset.seed(42)\nn_obs &lt;- 1000\n\ndata_class_a &lt;- tibble(\n  x = rnorm(n_obs, mean = 2, sd = 1),\n  y = -2 * x + 5 + rnorm(n_obs, mean = 0, sd = 1)\n) %&gt;%\n  mutate(classe = \"A\")\n\ndata_class_b &lt;- tibble(\n  x = rnorm(n_obs, mean = 4, sd = 1),\n  y = -2 * x + 6 + rnorm(n_obs, mean = 2, sd = 1)\n) %&gt;%\n  mutate(classe = \"B\")\n\n# Unir os dataframes e misturar\ndados_simulados &lt;- bind_rows(data_class_a, data_class_b) %&gt;%\n  sample_frac(1)\n\nhead(dados_simulados)\n\n# A tibble: 6 × 3\n      x      y classe\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; \n1  3.33 -0.793 A     \n2  5.29 -0.231 B     \n3  5.44 -2.31  B     \n4  2.27  0.226 A     \n5  2.85  2.13  B     \n6  1.46  3.33  A     \n\n\nUm ponto imporante aqui, vamos realizar o comando glimpse() para entender melhor a estrutura dos dados.\n\nglimpse(dados_simulados)\n\nRows: 2,000\nColumns: 3\n$ x      &lt;dbl&gt; 3.3349126, 5.2911413, 5.4366347, 2.2736953, 2.8548681, 1.464412…\n$ y      &lt;dbl&gt; -0.7925305, -0.2313488, -2.3086814, 0.2255405, 2.1270237, 3.326…\n$ classe &lt;chr&gt; \"A\", \"B\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"A\", \"B\", \"B\"…\n\n\nObservemos que a variável classe é do tipo character. Para que o modelo de classificação funcione corretamente, precisamos convertê-la para o tipo factor. Façamos então:\n\ndados_simulados$classe &lt;- as.factor(dados_simulados$classe)\nglimpse(dados_simulados)\n\nRows: 2,000\nColumns: 3\n$ x      &lt;dbl&gt; 3.3349126, 5.2911413, 5.4366347, 2.2736953, 2.8548681, 1.464412…\n$ y      &lt;dbl&gt; -0.7925305, -0.2313488, -2.3086814, 0.2255405, 2.1270237, 3.326…\n$ classe &lt;fct&gt; A, B, B, A, B, A, B, A, B, A, A, B, B, A, A, B, B, B, B, A, A, …\n\n\nAgora sim, a variável classe está como factor, o que é essencial para o modelo de classificação.\nPara entender melhor os dados que acabamos de criar, vamos visualizá-los. O gráfico a seguir mostra a distribuição dos pontos no plano cartesiano. Podemos ver que as duas classes formam dois “aglomerados” distintos.\n\nggplot(dados_simulados, aes(x = x, y = y)) +\n  geom_point(size = 3, alpha = 0.7) \n\n\n\n\n\n\n\n\nNesse próximo gráfico, podemos observar cada uma das classes sendo representadas por uma cor. De fato, a diferença de aglomerados visto no gráfico anterior sugere a diferença entre os dois grupos.\n\nggplot(dados_simulados, aes(x = x, y = y, color = classe)) +\n  geom_point(size = 3, alpha = 0.7) \n\n\n\n\n\n\n\n\n\n5.3.1 Preparando os Dados para o Modelo\nAntes de treinar o modelo, é uma prática essencial dividir o nosso conjunto de dados em dois subconjuntos: treino e teste.\n\nO conjunto de treino é usado para “ensinar” o modelo a identificar padrões.\nO conjunto de teste é usado para avaliar o desempenho do modelo em dados que ele nunca viu antes, garantindo uma avaliação mais realista.\n\n\n# 2. Dividir os dados em treino e teste\nsplit_simulado &lt;- initial_split(dados_simulados, prop = 0.7, strata = classe)\ntrain_simulado &lt;- training(split_simulado)\ntest_simulado &lt;- testing(split_simulado)\n\n\ndim(train_simulado)\n\n[1] 1400    3\n\ndim(test_simulado)\n\n[1] 600   3\n\n\n\n\n5.3.2 Treinando e Avaliando o Modelo de Regressão Logística\nAgora, vamos usar a biblioteca tidymodels para construir, treinar e avaliar o nosso modelo de Regressão Logística, que é um algoritmo de classificação linear.\n\n# 3. Treinar o modelo de regressão logística nos dados de TREINO\nmodelo_logistico_simples &lt;- logistic_reg() %&gt;%\n  fit(classe ~ x + y, data = train_simulado)\n\n# Fazer previsões nos dados de TREINO\npreds_train &lt;- predict(modelo_logistico_simples, new_data = train_simulado) %&gt;%\n  bind_cols(train_simulado)\n\n\n\n5.3.3 Visualizando a Fronteira de Decisão\nA grande vantagem de usar dados sintéticos é que podemos visualizar a “fronteira de decisão” que o modelo encontrou para separar as duas classes. A Regressão Logística sempre encontrará uma linha reta para fazer essa separação.\n\n# 5. Fazer previsões nos dados de TESTE}\npreds_test &lt;- predict(modelo_logistico_simples, new_data = test_simulado) %&gt;%\n  bind_cols(test_simulado)\n\n\n# 6. Extrair os coeficientes para a reta de classificação\nintercept &lt;- modelo_logistico_simples$fit$coefficients[\"(Intercept)\"]\ncoef_x &lt;- modelo_logistico_simples$fit$coefficients[\"x\"]\ncoef_y &lt;- modelo_logistico_simples$fit$coefficients[\"y\"]\n\n# A reta de decisão é onde a probabilidade é 0.5, ou seja, -intercept = coef_x*x + coef_y*y\n# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)\nslope &lt;- -coef_x / coef_y\nintercept_line &lt;- -intercept / coef_y\n\n# 7. Visualizar os dados e a reta de classificação\nggplot(dados_simulados, aes(x = x, y = y, color = classe)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(intercept = intercept_line, slope = slope, linetype = \"dashed\", size = 1, color = \"black\") +\n  labs(\n    title = \"Classificação Linear com Regressão Logística\",\n    subtitle = \"A reta pontilhada é a fronteira de decisão do modelo\",\n    x = \"Variável X\",\n    y = \"Variável Y\",\n    color = \"Classe\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n5.3.4 Avaliando o Desempenho do Modelo\nUma das ferramentas mais importantes para avaliar um modelo de classificação é a Matriz de Confusão. Ela mostra o quão bem o modelo classificou as amostras, comparando as classes previstas com as classes reais.\n\nVerdadeiros Positivos (TP): Predições corretas da classe positiva.\nVerdadeiros Negativos (TN): Predições corretas da classe negativa.\nFalsos Positivos (FP): Erro tipo I. Predições incorretas da classe positiva.\nFalsos Negativos (FN): Erro tipo II. Predições incorretas da classe negativa.\n\n\n# 8. Calcular a matriz de confusão\n\nmatriz_confusao &lt;- conf_mat(preds_train, truth = classe, estimate = .pred_class)\nmatriz_confusao\n\n          Truth\nPrediction   A   B\n         A 682  22\n         B  18 678\n\nmatriz_confusao_teste &lt;- conf_mat(preds_test, truth = classe, estimate = .pred_class)\nmatriz_confusao_teste\n\n          Truth\nPrediction   A   B\n         A 283   8\n         B  17 292\n\n\n\nautoplot(matriz_confusao_teste, type = \"heatmap\") +\n  labs(title = \"Matriz de Confusão (Dados de Teste)\")\n\n\n\n\n\n\n\n\nAlém da matriz de confusão, podemos usar outras métricas para uma avaliação mais completa:\n\nAcurácia (Accuracy): Proporção de predições corretas em relação ao total.\nPrecisão (Precision): A proporção de predições positivas que estavam corretas.\nRecall (Sensibilidade): A proporção de casos positivos reais que foram identificados corretamente.\nF1-Score: Média harmônica de Precisão e Recall.\n\n\naccuracy(preds_test, truth = classe, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.958\n\nprecision(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.945\n\nrecall(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary         0.973\n\nf_meas(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary         0.959\n\n\n\nminhas_metricas &lt;- metric_set(accuracy, precision, recall, f_meas)\n\n# Calcular e exibir as métricas nos dados de teste\nminhas_metricas(preds_test, truth = classe, estimate = .pred_class)\n\n# A tibble: 4 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.958\n2 precision binary         0.973\n3 recall    binary         0.943\n4 f_meas    binary         0.958",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "04-pratica.html#classificação-com-dados-não-lineares-árvore-de-decisão",
    "href": "04-pratica.html#classificação-com-dados-não-lineares-árvore-de-decisão",
    "title": "5  Modelo de Classificação",
    "section": "5.4 2. Classificação com Dados Não-Lineares (Árvore de Decisão)",
    "text": "5.4 2. Classificação com Dados Não-Lineares (Árvore de Decisão)\nE se os dados não puderem ser separados por uma linha reta? Vamos gerar um novo conjunto de dados onde as classes se “cruzam” e testar a Regressão Logística novamente, para então compará-la com um modelo mais flexível: a Árvore de Decisão.\n\n5.4.1 Gerando Dados Não-Lineares\n\n# 1. Gerar dados sintéticos para duas classes\n\nset.seed(42)\nn_obs &lt;- 1000\n\ndata_class_a &lt;- tibble(\n  x = rnorm(n_obs, mean = 4, sd = 1),\n  y = -2 * x + 16 + rnorm(n_obs, mean = 0, sd = 1)\n) %&gt;%\n  mutate(classe = \"A\")\n\ndata_class_b &lt;- tibble(\n  x = rnorm(n_obs, mean = 4, sd = 1),\n  y = 2 * x + rnorm(n_obs, mean = 2, sd = 1)\n) %&gt;%\n  mutate(classe = \"B\")\n\n# Unir os dataframes e misturar\ndados_simulados &lt;- bind_rows(data_class_a, data_class_b) %&gt;%\n  sample_frac(1)\n\nhead(dados_simulados)\n\n# A tibble: 6 × 3\n      x     y classe\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n1  5.33  6.21 A     \n2  5.29 14.9  B     \n3  5.44 13.4  B     \n4  4.27  7.23 A     \n5  2.85  7.55 B     \n6  3.46 10.3  A     \n\n\nVamos plotar esses novos dados.\n\nggplot(dados_simulados, aes(x = x, y = y)) +\n  geom_point(size = 3, alpha = 0.7) \n\n\n\n\n\n\n\n\nAgora colorindo cada uma das classes.\n\nggplot(dados_simulados, aes(x = x, y = y, color = classe)) +\n  geom_point(size = 3, alpha = 0.7) \n\n\n\n\n\n\n\n\nPerceba que as classes A e B não são separáveis por uma única linha reta.\n\n\n5.4.2 Regressão Logística em Dados Não-Lineares\nAgora, vamos tentar aplicar o mesmo modelo de Regressão Logística. A fronteira de decisão será uma linha reta, mas veremos que ela não conseguirá separar bem as classes.\n\n# 2. Treinar um modelo de regressão logística\ndados_simulados$classe &lt;- as.factor(dados_simulados$classe)\n\n# 3. Dividir os dados em treino e teste\nsplit_simulado &lt;- initial_split(dados_simulados, prop = 0.7, strata = classe)\ntrain_simulado &lt;- training(split_simulado)\ntest_simulado &lt;- testing(split_simulado)\n\n\ndim(train_simulado)\n\n[1] 1400    3\n\ndim(test_simulado)\n\n[1] 600   3\n\n\n\n# 4. Treinar o modelo de regressão logística nos dados de TREINO\nmodelo_logistico_simples &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  set_mode(\"classification\") %&gt;%\n  fit(classe ~ x + y, data = train_simulado)\n\n# Fazer previsões nos dados de TREINO\npreds_train &lt;- predict(modelo_logistico_simples, new_data = train_simulado) %&gt;%\n  bind_cols(train_simulado)\n\n# 5. Fazer previsões nos dados de TESTE\npreds_test &lt;- predict(modelo_logistico_simples, new_data = test_simulado) %&gt;%\n  bind_cols(test_simulado)\n\n\n# 6. Extrair os coeficientes para a reta de classificação\nintercept &lt;- modelo_logistico_simples$fit$coefficients[\"(Intercept)\"]\ncoef_x &lt;- modelo_logistico_simples$fit$coefficients[\"x\"]\ncoef_y &lt;- modelo_logistico_simples$fit$coefficients[\"y\"]\n\n# A reta de decisão é onde a probabilidade é 0.5, ou seja, -intercept = coef_x*x + coef_y*y\n# Isolamos 'y' para plotar a reta: y = (-coef_x/coef_y)*x - (intercept/coef_y)\nslope &lt;- -coef_x / coef_y\nintercept_line &lt;- -intercept / coef_y\n\n# 7. Visualizar os dados e a reta de classificação\nggplot(dados_simulados, aes(x = x, y = y, color = classe)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_abline(intercept = intercept_line, slope = slope, linetype = \"dashed\", size = 1, color = \"black\") +\n  labs(\n    title = \"Classificação Linear com Regressão Logística\",\n    subtitle = \"A reta pontilhada é a fronteira de decisão do modelo\",\n    x = \"Variável X\",\n    y = \"Variável Y\",\n    color = \"Classe\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n# 8. Calcular a matriz de confusão\n\nmatriz_confusao &lt;- conf_mat(preds_train, truth = classe, estimate = .pred_class)\nmatriz_confusao\n\n          Truth\nPrediction   A   B\n         A 480 238\n         B 220 462\n\nmatriz_confusao &lt;- conf_mat(preds_test, truth = classe, estimate = .pred_class)\nmatriz_confusao\n\n          Truth\nPrediction   A   B\n         A 204 114\n         B  96 186\n\n\n\nautoplot(matriz_confusao, type = \"heatmap\")\n\n\n\n\n\n\n\n\nVamos ver algumas métricas, como acurácia, precisão, recall e F1-score.\n\naccuracy(preds_test, truth = classe, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary          0.65\n\nprecision(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.660\n\nrecall(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary          0.62\n\nf_meas(preds_test, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary         0.639\n\n\nComo esperado, a matriz de confusão e as métricas de desempenho mostram que o modelo teve dificuldade em separar os dados.\n\n\n5.4.3 Árvore de Decisão em Dados Não-Lineares\nAgora, vamos usar uma Árvore de Decisão, um modelo de classificação que não é restrito a fronteiras lineares.\n\n# 1. Definir o modelo de árvore de decisão (rpart)\ntree_model &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n# 2. Criar o workflow\ntree_workflow &lt;- workflow() %&gt;%\n  add_model(tree_model) %&gt;%\n  add_formula(classe ~ .)\n\n# 3. Ajustar (treinar) o modelo\ntree_fit &lt;- fit(tree_workflow, data = train_simulado)\n\n# 4. Fazer previsões\ntree_pred &lt;- predict(tree_fit, new_data = test_simulado) %&gt;%\n  bind_cols(test_simulado)\n\n# 5. Gerar a matriz de confusão\nconf_mat(tree_pred, truth = classe, estimate = .pred_class)\n\n          Truth\nPrediction   A   B\n         A 254  37\n         B  46 263\n\n\n\n# 4. Fazer previsões nos dados de TREINO\ntree_pred_train &lt;- predict(tree_fit, new_data = train_simulado) %&gt;%\n  bind_cols(train_simulado)\n\n# 5. Gerar a matriz de confusão para os dados de TREINO\nconf_mat(tree_pred_train, truth = classe, estimate = .pred_class)\n\n          Truth\nPrediction   A   B\n         A 599  71\n         B 101 629\n\n\n\naccuracy(tree_pred, truth = classe, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.862\n\nprecision(tree_pred, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.851\n\nrecall(tree_pred, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary         0.877\n\nf_meas(tree_pred, truth = classe, estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary         0.864\n\n\nPerceba que a acurácia do modelo de Árvore de Decisão foi significativamente maior! Isso acontece porque ele pode criar fronteiras de decisão complexas, que não são apenas linhas retas.\n\n\n5.4.4 Visualizando as Fronteiras de Decisão da Árvore\nPara entender como a Árvore de Decisão classificou os dados, vamos plotar as regiões de decisão. O resultado é uma área segmentada em retângulos, onde cada retângulo representa a previsão de uma classe.\n\n# 1. Criar uma grade de pontos para o plano 2D (x e y)\n# Definimos os limites da grade com base nos valores mínimos e máximos dos dados\ngrid &lt;- expand.grid(\n  x = seq(min(dados_simulados$x) - 1, max(dados_simulados$x) + 1, length.out = 100),\n  y = seq(min(dados_simulados$y) - 1, max(dados_simulados$y) + 1, length.out = 100)\n)\n\n# 2. Fazer as previsões para cada ponto na grade usando o modelo de árvore\ngrid_preds_tree &lt;- predict(tree_fit, new_data = grid, type = \"class\") %&gt;%\n  bind_cols(grid)\n\n# 3. Plotar as fronteiras de decisão e os dados originais\nggplot() +\n  # Camada para as fronteiras de decisão\n  geom_raster(data = grid_preds_tree, aes(x = x, y = y, fill = .pred_class), alpha = 0.5) +\n  # Camada para os pontos de dados originais\n  geom_point(data = dados_simulados, aes(x = x, y = y, color = classe), size = 2) +\n  # Adicionando rótulos e título\n  labs(\n    title = \"Fronteiras de Decisão da Árvore de Decisão\",\n    subtitle = \"Regiões de previsão do modelo de árvore\",\n    x = \"Variável X\",\n    y = \"Variável Y\",\n    fill = \"Classe Prevista\",\n    color = \"Classe Real\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nPodemos visualizar a árvore com as perguntas feitas.\n\n# O pacote rpart.plot ajuda a visualizar a árvore\n# install.packages(\"rpart.plot\")\nlibrary(rpart.plot)\n\nCarregando pacotes exigidos: rpart\n\n\n\nAnexando pacote: 'rpart'\n\n\nO seguinte objeto é mascarado por 'package:dials':\n\n    prune\n\nrpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "04-pratica.html#classificação-pinguins-do-arquipélago-palmer",
    "href": "04-pratica.html#classificação-pinguins-do-arquipélago-palmer",
    "title": "5  Modelo de Classificação",
    "section": "5.5 Classificação: Pinguins do arquipélago Palmer",
    "text": "5.5 Classificação: Pinguins do arquipélago Palmer\nAgora que você entendeu os conceitos básicos, vamos aplicar o mesmo fluxo de trabalho em um conjunto de dados real: as medições dos pinguins da Antártida. Nosso objetivo será classificar a espécie do pinguim com base em suas características físicas.\nUtilizaremos os dados de pingAins do arquipélago Palmer, visto no capítulo anterior. Podemos, novamente, acessar esses dados através do pacote palmerpenguins.\n\nlibrary(palmerpenguins)\n\n\nAnexando pacote: 'palmerpenguins'\n\n\nO seguinte objeto é mascarado por 'package:modeldata':\n\n    penguins\n\n\nOs seguintes objetos são mascarados por 'package:datasets':\n\n    penguins, penguins_raw\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nNosso objetivo será classificar a espécie do pinguim com base em suas características físicas.\n\n5.5.1 Preparando os Dados\nAntes de modelar, precisamos tratar os valores ausentes (NA) e dividir os dados.\n\n# Removendo linhas com valores ausentes (NA)\npenguins &lt;- na.omit(penguins)\nglimpse(penguins)\n\nRows: 333\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6…\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2…\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800…\n$ sex               &lt;fct&gt; male, female, female, female, male, female, male, fe…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\n5.5.2 Aplicação de um modelo de classificação\n\n# Criar um split treino/teste\nset.seed(123)\nsplit &lt;- initial_split(penguins, prop = 0.7, strata = species)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\n\ndim(train)\n\n[1] 232   8\n\ndim(test)\n\n[1] 101   8\n\n\n\n\n5.5.3 Aplicação de um modelo de classificação: Regressão Logística Multinomial\nVamos agora aplicar a regressão logística multinomial aos dados dos pinguins. Este modelo é uma extensão da regressão logística binária, que permite classificar dados em três ou mais categorias.\n\n# 1. Definir o modelo de regressão logística multinomial\n# O 'set_engine(\"nnet\")' especifica o pacote que será usado para o cálculo\nmodelo_multinomial &lt;- multinom_reg() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"classification\")\n\n# 2. Criar o workflow (fluxo de trabalho)\n# O 'add_formula(species ~ .)' diz ao modelo para usar todas as outras variáveis\n# para prever a espécie (species)\nworkflow_multinomial &lt;- workflow() %&gt;%\n  add_model(modelo_multinomial) %&gt;%\n  add_formula(species ~ .)\n\n# 3. Ajustar (treinar) o modelo com os dados de TREINO\n# O 'fit()' executa o treinamento do modelo\najustado_multinomial &lt;- fit(workflow_multinomial, data = train)\n\n# 4. Fazer previsões nos dados de TESTE\n# O 'predict()' usa o modelo treinado para prever a espécie nos dados de teste\npred_multinomial &lt;- predict(ajustado_multinomial, new_data = test) %&gt;%\n  bind_cols(test)\n\n# 5. Avaliar o desempenho com a Matriz de Confusão\n# A 'conf_mat()' compara as previsões (.pred_class) com a realidade (species)\nmatriz_confusao_multinomial &lt;- conf_mat(pred_multinomial, truth = species, estimate = .pred_class)\nmatriz_confusao_multinomial\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie        43         0      0\n  Chinstrap      1        21      0\n  Gentoo         0         0     36\n\n\nA matriz de confusão acima mostra o desempenho do modelo em prever a espécie de pinguim. Cada linha representa a espécie real, e cada coluna representa a espécie prevista. Os valores na diagonal mostram o número de acertos do modelo para cada espécie.\nPara uma avaliação mais completa, também podemos verificar as principais métricas de classificação.\n\n# Métricas de desempenho\nmetrics(pred_multinomial, truth = species, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.990\n2 kap      multiclass     0.985\n\n\n\n\n5.5.4 Treinando e Avaliando o Modelo de Árvore de Decisão\nVamos usar uma Árvore de Decisão para este exemplo, pois ela é intuitiva e a visualização da árvore ajuda a entender o processo de tomada de decisão.\n\n# Exemplo com Árvore de Decisão (mais visual para iniciantes)\n\n# 1. Definir o modelo de árvore de decisão (rpart)\ntree_model &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n# 2. Criar o workflow\ntree_workflow &lt;- workflow() %&gt;%\n  add_model(tree_model) %&gt;%\n  add_formula(species ~ .)\n\n# 3. Ajustar (treinar) o modelo\ntree_fit &lt;- fit(tree_workflow, data = train)\n\n# 4. Fazer previsões\ntree_pred &lt;- predict(tree_fit, new_data = test) %&gt;%\n  bind_cols(test)\n\n# 5. Gerar a matriz de confusão\nconf_mat(tree_pred, truth = species, estimate = .pred_class)\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie        42         1      0\n  Chinstrap      2        16      0\n  Gentoo         0         4     36\n\n\nVocê também pode extrair as métricas de desempenho:\n\nmetrics(tree_pred, truth = species, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.931\n2 kap      multiclass     0.891\n\n\n\n\n5.5.5 Visualizando a Árvore de Decisão\nA beleza da Árvore de Decisão é que podemos visualizar o conjunto de regras que ela aprendeu. Cada nó representa uma decisão baseada em uma variável (por exemplo, flipper_length_mm).\n\n# O pacote rpart.plot ajuda a visualizar a árvore\n# install.packages(\"rpart.plot\")\nlibrary(rpart.plot)\nrpart.plot(extract_fit_engine(tree_fit$fit$fit, roundint = FALSE))\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\nA visualização da árvore mostra o caminho que o modelo segue para classificar cada pinguim. Por exemplo, se o comprimento da nadadeira (flipper_length_mm) for maior ou igual a 207 mm e a profundidade do bico (bill_depth_mm) for maior ou igual a 17 mm, o pinguim será classificado como Chistrap.\nEste exemplo ilustra como modelos de classificação podem ser usados para resolver problemas práticos e como a visualização pode ser uma ferramenta poderosa para interpretar os resultados.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelo de Classificação</span>"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "2  Introdução",
    "section": "",
    "text": "2.1 O que é ciência de dados?\nNeste primeiro capítulo, vamos mergulhar em alguns aspectos fundamentais para adentrarmos ao mundo da Ciência de Dados.\nAntes de colocarmos a mão na massa com o R e o RStudio nos próximos capítulos, é importante entendermos o que está por trás dessa área. Vamos explorar alguns conceitos principais, como inteligência artificial e aprendizado de máquina, e explorar os diferentes papéis e caminhos que uma carreira em dados pode oferecer. Ao final, você terá uma base sólida para dar os primeiros passos e se preparar para a jornada prática que nos aguarda.\nA Ciência de Dados é uma área interdisciplinar que utiliza métodos científicos, processos e algoritmos para extrair conhecimento e padrões de dados, tanto estruturados (organizados em planilhas) quanto não estruturados (imagens, sons, sites, etc.). Em essência, é a combinação de estatística, programação e conhecimento de domínio para solucionar problemas e guiar a tomada de decisões.\nO trabalho de um cientista de dados abrange todo o ciclo de vida dos dados, desde a coleta e a limpeza, passando pela análise exploratória e a modelagem, até a comunicação dos resultados. Essa jornada pode envolver a busca por dados em bases públicas (como as do IBGE), a participação em competições (como no Kaggle) ou a utilização de repositórios colaborativos (como a Base dos Dados).\nDentro da área, existem diferentes carreiras:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-intro.html#o-que-é-ciência-de-dados",
    "href": "01-intro.html#o-que-é-ciência-de-dados",
    "title": "2  Introdução",
    "section": "",
    "text": "Cientista de Dados: Foca na análise e na modelagem de dados para extrair informações, usando conhecimentos de estatística e algoritmos de machine learning.\nEngenheiro de Dados: Responsável por construir e manter a infraestrutura (bancos de dados, pipelines) que permite que os dados sejam coletados, processados e acessados de forma eficiente.\nAnalista de Dados: Focado em explorar e visualizar dados para responder a perguntas de negócio, geralmente usando ferramentas como o Power BI ou o Tableau.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-intro.html#inteligência-artificial-aprendizado-de-máquina-e-aprendizado-profundo",
    "href": "01-intro.html#inteligência-artificial-aprendizado-de-máquina-e-aprendizado-profundo",
    "title": "2  Introdução",
    "section": "2.2 Inteligência Artificial, Aprendizado de Máquina e Aprendizado Profundo",
    "text": "2.2 Inteligência Artificial, Aprendizado de Máquina e Aprendizado Profundo\nEsses termos são frequentemente usados de forma intercambiável, mas têm significados distintos. Para sermos mais precisos, cada termo a seguir engloba o próximo termo como um subconjunto:\n\nInteligência Artificial (IA): O conceito mais amplo. É a ciência de criar máquinas ou programas que podem simular a inteligência humana, resolvendo problemas, tomando decisões e interagindo com o ambiente.\nAprendizado de Máquina (Machine Learning - ML): Um subcampo da IA. Trata-se da construção de modelos que aprendem padrões a partir de dados, sem serem explicitamente programados para cada tarefa. Em vez de seguir um conjunto de regras fixas, o modelo aprende e se ajusta com base nos exemplos que recebe.\nAprendizado Profundo (Deep Learning - DL): Um subcampo do ML. Utiliza redes neurais artificiais com múltiplas camadas (por isso o “profundo”) para analisar dados. É especialmente eficaz em tarefas complexas, como reconhecimento de imagem e processamento de linguagem natural.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "01-intro.html#o-que-é-aprendizado-de-máquina",
    "href": "01-intro.html#o-que-é-aprendizado-de-máquina",
    "title": "2  Introdução",
    "section": "2.3 O que é aprendizado de máquina?",
    "text": "2.3 O que é aprendizado de máquina?\nO Aprendizado de Máquina (em inglês Machine Learning, ML) é a capacidade de um sistema computacional aprender e melhorar a partir da experiência, ou seja, a partir dos dados. Ao invés de escrever regras manuais e inflexíveis para cada situação, você “treina” um modelo para que ele descubra e generalize os padrões presentes nos dados.\nImagine que você quer criar um filtro de spam para e-mails. A abordagem clássica seria escrever uma regra: “Se o e-mail contiver as palavras ‘ganhar dinheiro’, ‘milionário’ e ‘clique aqui’, marque-o como spam”. A abordagem de machine learning é diferente: você alimenta o modelo com milhares de e-mails já classificados como “spam” ou “não spam” e deixa que ele aprenda quais características são mais importantes para fazer essa distinção. O modelo pode descobrir padrões muito mais sutis e complexos que um humano não conseguiria definir em regras.\n\n2.3.1 Por que o ML é importante?\nO machine learning impulsiona muitas das tecnologias que usamos diariamente, como:\n\nSistemas de recomendação: A Netflix sugere filmes e o Spotify recomenda músicas baseados no que você já consumiu.\nDetecção de fraude: Bancos usam modelos de ML para identificar transações suspeitas em tempo real.\nCarros autônomos: Veículos que usam ML para reconhecer objetos, pedestres e sinais de trânsito, tomando decisões instantâneas.\nAvanços científicos: O AlphaFold 2, por exemplo, usou aprendizado profundo para prever a estrutura de proteínas com uma precisão incrível, acelerando a pesquisa em biologia e medicina.\n\n\n\n2.3.2 Tipos de Aprendizado de Máquina\n\nAprendizado Supervisionado: O modelo aprende a partir de dados que já possuem um “rótulo” ou “resposta” correta. O objetivo é prever essa resposta para novos dados. É o caso do filtro de spam, onde você sabe quais e-mails são spam e quais não são.\nAprendizado Não Supervisionado: O modelo trabalha com dados que não têm rótulos. O objetivo é encontrar padrões e estruturas ocultas. Um exemplo é a segmentação de clientes, onde você agrupa clientes com comportamentos parecidos, sem saber de antemão qual é o “grupo” correto.\nAprendizado Semi-Supervisionado: Uma combinação dos dois anteriores. O modelo usa um conjunto pequeno de dados rotulados e um grande conjunto de dados não rotulados para aprender padrões. Útil quando rotular dados é caro ou demorado.\nAprendizado por Reforço: O modelo aprende através de tentativa e erro, interagindo com um ambiente para maximizar uma recompensa. É a técnica por trás de robôs que aprendem a andar ou de sistemas de IA que jogam xadrez.\n\n\n\n2.3.3 Boas práticas para a carreira de Ciência de Dados\nPara quem está começando, algumas atitudes podem fazer toda a diferença no mercado de trabalho:\n\nOlhe os requisitos das vagas: Analise as descrições de vagas de ciência de dados para entender quais são as habilidades mais demandadas, como linguagens de programação (R ou Python), conhecimento de SQL, ferramentas de visualização e frameworks de machine learning.\nCrie e mantenha um portfólio no GitHub: O GitHub é essencial para cientistas de dados. Crie um perfil e use-o para mostrar projetos pessoais, códigos e análises. Ter um portfólio demonstra suas habilidades na prática, muito além do que um currículo pode dizer.\nMantenha seu LinkedIn atualizado: O LinkedIn é a principal rede para conexões profissionais. Mantenha seu perfil completo, compartilhe seu portfólio, publique artigos ou insights sobre a área e conecte-se com outros profissionais para construir sua rede de contatos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html",
    "href": "02-fundamentos.html",
    "title": "3  Fundamentos de R",
    "section": "",
    "text": "3.1 O que são R e RStudio?\nPara começar essa jornada, o primeiro passo é configurar o ambiente de trabalho. Isso envolve a instalação de dois softwares distintos, mas que trabalham juntos: R e RStudio. Compreender o funcionamento de cada um e como eles se interagem é fundamental para as próximas etapas.\nÉ comum que iniciantes confundam R e RStudio, mas esta distinção é crucial para o processo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#o-que-são-r-e-rstudio",
    "href": "02-fundamentos.html#o-que-são-r-e-rstudio",
    "title": "3  Fundamentos de R",
    "section": "",
    "text": "R é a linguagem de programação e o ambiente de software para computação estatística e gráficos. Pode-se pensar que é o “motor” que executa todos os cálculos, análises e gera os gráficos. Além de tudo, é um projeto de código aberto, gratuito e mantido por uma vasta comunidade de desenvolvedores e estatísticos ao redor do mundo.\nRStudio é um Ambiente de Desenvolvimento Integrado (IDE, do inglês Integrated Development Environment). Se o R é o motor do carro, o RStudio1 é o painel, o volante, e todo o interior que torna a condução do carro uma experiência agradável e gerenciável. O RStudio fornece uma interface gráfica e amigável que organiza o trabalho em R, facilitando a escrita de scripts (arquivos de códigos), a visualização de gráficos, o gerenciamento de pacotes (bibliotecas) e muito mais. Embora seja possível utilizar o R sem o RStudio, a utilização do RStudio é fortemente recomendada, pois deixa o processo de análise muito mais interativo e organizado.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#instalação-passo-a-passo",
    "href": "02-fundamentos.html#instalação-passo-a-passo",
    "title": "3  Fundamentos de R",
    "section": "3.2 Instalação passo a passo",
    "text": "3.2 Instalação passo a passo\nA instalação adequada dos programas é um pré-requisito crucial. A ordem de instalação é importante: R deve ser instalado antes do RStudio.\n\nInstalando o R:\n\n\nAcesse o site do Comprehensive R Archive Network (CRAN)2, que é o repositório oficial para o R e seus pacotes.\nNa página inicial, selecione o link de download para o seu sistema operacional (Linux, macOS ou Windows).\nSiga as instruções para baixar a versão mais recente (“base”). É crucial baixar a versão diretamente do CRAN, pois os gerenciadores de pacotes de alguns sistemas operacionais (como o get-apt do Ubuntu) podem fornecer versões desatualizadas.\nExecute o arquivo de instalação baixado e siga as instruções padrão, aceitando as configurações padrão.\n\n\n\nInstalando o RStudio:\n\n\nApós a instalação do R, acesse o site da Posit e clique para baixar a versão gratuita do RStudio Desktop.\nBaixe o instalador apropriado para o seu sistema operacional.\nExecute o arquivo de instalação. O RStudio detectará automaticamente a instalação do R existente.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#navegando-na-interface-do-rstudio",
    "href": "02-fundamentos.html#navegando-na-interface-do-rstudio",
    "title": "3  Fundamentos de R",
    "section": "3.3 Navegando na interface do RStudio",
    "text": "3.3 Navegando na interface do RStudio\nAo abrir o RStudio pela primeira vez, a interface se apresenta dividida em quatro painéis ou quadrantes principais, cada um com uma função específica:\n\nEditor de scripts (Superior esquerdo): Este é o seu principal espaço de trabalho. Aqui, você escreverá e salvará seus scripts R (arquivos com extensão .R). Trabalhar em um script, em vez de digitar comandos diretamente no console, é a base da ciência reprodutível, pois permite salvar, comentar e reutilizar seu código.\nConsole (Inferior esquerdo): O console é o código R é efetivamente executado. Você pode digitar os comandos diretamente nele para testes rápidos ou executar linhas de códigos do seu script (utilizando o atalho Ctrl+Enter). A saída dos comandos também aparecerá aqui.\nAmbiente e Histórico (Superior direito): A aba Environment mostra todos os objetos (como datasets, variáveis, etc.) que foram criadas na sessão atual do R. Já a aba History mantém um registro de todos os comandos utilizados.\nArquivos, Gráficos, Pacotes e Ajuda (Inferior direita): Este painel multifuncional permite navegar pelos arquivos do seu computador (Files) , visualizar gráficos gerados (Plots), gerenciar pacotes instalados (Packages), e acessar documentações de ajuda do R (Help).\n\nÉ importante salientar que o RStudio permite customizações, como a alteração das posições dos painéis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#o-conceito-de-pacotes",
    "href": "02-fundamentos.html#o-conceito-de-pacotes",
    "title": "3  Fundamentos de R",
    "section": "3.4 O conceito de pacotes",
    "text": "3.4 O conceito de pacotes\nA grande força do R reside em seu ecossistema de pacotes. Um pacote é a coleção de funções, dados e documentação que estende as capacidades iniciais do R. Para qualquer tarefa estatística ou de manipulação de dados que se possa imaginar, provavelmente existe algum pacote que a facilita.\n\n3.4.1 Instalando e Carregando Pacotes Essenciais\nExiste uma distinção básica a ser realizada entre instalar e carregar um pacote.\n\nInstalação: É o ato de baixar o pacote do CRAN e instalá-lo no computador. Isso é realizado apenas uma vez para cada pacote.\nCarregamento: É o ato de carregar o pacote instalado em sua sessão do R de forma que as funções adicionais fiquem disponíveis para uso. Isso precisa ser feito toda vez que uma sessão no R é iniciada.\n\nPara este material, os pacotes centrais são: tidyverse, lme4, lmerTest e nlme. Um dos métodos para instalar pacotes R no computador é por meio da função install.packages():\n\n\n# Instala o pacote tidyverse, que inclui dplyr, ggplot2 e outros\ninstall.packages(\"tidyverse\")\n\n# Instala o pacote para modelos lineares mistos\ninstall.packages(\"lme4\")\n\n# Instala outros pacotes para modelos mistos\ninstall.packages(\"lmerTest\")\ninstall.packages(\"nlme\")\n\nApós a instalação, para usar as funções de um pacote, é preciso carregá-lo com a função library():\n\nlibrary(tidyverse)\n\nCabe ressaltar que, ao longo do uso de diversos pacotes, podem ocorrer conflitos de funções com o mesmo nome. Nesses casos, a solução mais prática é utilizar a notação pacote::funcao para indicar explicitamente ao R de qual biblioteca desejamos chamar a função.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#diretório-de-trabalho-e-projetos-rstudio",
    "href": "02-fundamentos.html#diretório-de-trabalho-e-projetos-rstudio",
    "title": "3  Fundamentos de R",
    "section": "3.5 Diretório de Trabalho e Projetos RStudio",
    "text": "3.5 Diretório de Trabalho e Projetos RStudio\nO diretório de trabalho é a pasta no seu computador onde o R irá procurar por arquivos para ler e onde, também, salvará os arquivos criados (como gráficos, scripts e datasets modificados). É possível identificar o diretório atual através do comando getwd() e, embora também seja possível defini-la manualmente com a função setwd(\"caminho/para/sua/pasta\"), essa prática não é aconselhável, visto que o uso de caminhos de arquivos absolutos torna o código não portável; ou seja, ele não irá funcionar se você mover a pasta do projeto ou tentá-la executá-lo em outro computador.\nA solução moderna e robusta para esse problema é a utilização de Projetos RStudio. Um projeto RStudio (extensão .Rproj) é um arquivo que você cria dentro de uma pasta do seu projeto de pesquisa. Ao abrir um projeto, o RStudio automaticamente define o diretório de trabalho para aquela pasta. Isso garante que todos os caminhos de arquivo do seu código possam ser relativos à raiz do projeto, tornando sua análise totalmente reprodutível e compartilhável de forma eficaz. Outra maneira de criar projetos é através do próprio RStudio, através das seguintes instruções File &gt; New Project &gt; New Directory &gt; New Project e nesta última etapa, você escolherá um nome para o projeto e a pasta de sua pesquisa, finalizando em Create Project. A criação de um projeto para cada análise de pesquisa é uma prática fundamental para a organização e a reprodutibilidade científica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#r-básico",
    "href": "02-fundamentos.html#r-básico",
    "title": "3  Fundamentos de R",
    "section": "3.6 R Básico",
    "text": "3.6 R Básico\nA leitura desta sessão é aconselhada para o leitor que nunca teve contato com o R. Os tópicos introduzidos são especiais para a compreensão do que é um dataframe, a estrutura dos datasets dentro do R, e quais operações estarão sendo realizadas quando estivermos efetuando filtragens e modificações de suas colunas. Também são importantes para a compreensão do que é uma função no R.\n\n3.6.1 Operadores Matemáticos\nOs operadores matemáticos, também conhecidos por operadores binários, dentro do ambiente R soam como familiares. A Tabela 3.1 exibe os operadores mais básicos utilizados.\nPara exemplificar como efetuar cálculos de expressões matemáticas no R, suponha que desenhamos calcular o valor de: \\[2\\times 2 + \\frac{4 + 4}{2}.\\] Para isso, escrevemos 2*2 + (4+4)/2 no console para determinarmos o resultado\n\n2*2 + (4+4)/2\n\n[1] 8\n\n\n\n\n\n\nTabela 3.1: Operadores matemáticos básicos.\n\n\n\n\n\n\nOperadores\nDescrição\n\n\n\n\n+\nAdição\n\n\n-\nSubtração\n\n\n*\nMultiplicação\n\n\n/\nDivisão\n\n\n^\nExponenciação\n\n\n\n\n\n\n\n\n\n\n3.6.2 Objetos e funções\nO R permite guardar valores dentro de um objeto. Um objeto é simplesmente um nome que guarda uma determinada informação na memória do computador, que é criado por meio do operador &lt;-. Veja que no código a seguir\n\nx &lt;- 10 # Salvando \"10\" em \"x\"\nx       # Avaliando o objeto \"x\"\n\n[1] 10\n\n\nfoi salvo que a informação que x carrega é o valor 10. Portanto, toda vez que o objeto x for avaliado, o R irá devolver o valor 10.\nÉ importante ressaltar que há regras para a nomeação dos objetos, dentre elas, não começar com números. Assim, todos os seguintes exemplos são permitidos: x &lt;- 1, x1 &lt;- 1, meu_objeto &lt;- 1, meu.objeto &lt;- 1. Ainda, o R diferencia letras minúsculas de maiúsculas, então objetos como y e Y são diferentes.\nEnquanto que os objetos são nomes que salvam informações de valores, funções são nomes que guardam informações de um código R, retornando algum resultado programado. A sintaxe básica de uma função é nome_funcao(arg1, arg2, ...). Os valores dentro dos parênteses são chamados por argumentos, que são informações necessárias para o bom funcionamento de uma função. Às vezes, uma função não necessita do fornecimento de argumentos específicos.\nUma função simples, porém útil, é a sum(). Ela consiste em somar os valores passados em seu argumento. Suponha que desejamos somar 1+2+3+4+5. Assim,\n\nsum(1,2,3,4,5)\n\n[1] 15\n\n\né possível reparar que o resultado é 15.\nA classe de um objeto é muito importante na programação em R. É a partir disso que as funções e operadores conseguem entender o que fazer com cada objeto. Há uma infinidade de classes, dentre as mais conhecidas são: numeric, character, data.frame, logical e factor. Para averiguar o tipo de classe, a função class() retorna exatamente a classe do objeto.\n\nclass(\"a\")\n\n[1] \"character\"\n\nclass(1)\n\n[1] \"numeric\"\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\n\n\n3.6.3 Importanto dados\nUma atividade importante para qualquer análise estatística que vier ser feita no R é importante importar os dados para o ambiente de trabalho, que ficarão guardados dentro de um objeto no projeto RStudio – afinal, como faríamos as análises sem os dados? No contexto da Biologia, isso costuma significar ler arquivos com medidas de peso, contagens de indivíduos, medidas de comprimento etc., geralmente armazenados em formatos de texto (.csv ou .tsv) ou planilhas (.xlsx). As principais funções para cada ocasião de arquivo são:\n\nCSV com cabeçalho:\n\n\ndados &lt;- read.csv(\"dados.csv\",\n  header = TRUE, # indica que há cabeçalho\n  sep    = \",\",  # separador vírgula\n  stringsAsFactors = FALSE # evita conversão automática em fatores\n)\n\n\nTXT ou TSV com tabulação:\n\n\ndados &lt;- read.delim(\"dadostsv\", \n  header = TRUE, \n  sep    = \"\\t\"\n)\n\n\nPlanilhas no Excel (arquivos .xlsx):\n\n\ndados &lt;- readxl::read_excel(\"dados.xlsx\",\n  sheet = \"Planilha1\" # aqui você escolhe a planilha a ser lida\n)\n\nRessaltamos, neste caso, a necessidade da utilização da biblioteca readxl para que seja possível lermos planilhas no R.\n\n\n3.6.4 Vetores e Data frames\nVetores são uma estrutura fundamental dentro do R, em especial, é a partir deles que os data frames são construídos. Por definição, são conjuntos indexados de valores e para criá-los, basta utilizar a função c() com valores separados por vírgula (ex.: c(1,2,4,10)). Para acessar um valor dentro de um determinado vetor, utiliza-se os colchetes []:\n\nvetor &lt;- c(\"a\", \"b\", \"c\")\n\n# Acessando valor \"b\"\nvetor[2]\n\n[1] \"b\"\n\n\nUm vetor só pode guardar um tipo de objeto e ele terá sempre a mesma classe dos objetos que guarda. Caso tentarmos misturar duas classes, o R vai apresentar o comportamento conhecido como coerção.\n\nclass(c(1,2,3))\n\n[1] \"numeric\"\n\nclass(vetor)\n\n[1] \"character\"\n\nclass(c(1,2,\"a\",\"b\"))\n\n[1] \"character\"\n\n\nNeste caso, todos os elementos do vetor se transformaram em texto.\nAssim, também, data frames são de extrema importância no R, visto que são os objetos que guardam os dados e são equivalentes a uma planilha do Excel. A principal característica é possuir linha e colunas. Em geral, as colunas são vetores de mesmo tamanho (ou dimensão). Um valor específico de um data frame pode ser acessado, também, via colchetes []:\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\nmtcars[1,2]\n\n[1] 6\n\n\nmtcars é um conjunto de dados muito conhecido na comunidade R.\n\n\n3.6.5 Fatores\nFatores são uma classe de objetos no R criada para representar variáveis categóricas numericamente. A característica que define essa classe é o atributo levels, que representam as possíveis categorias de uma variável categórica.\nA título de exemplificação, considere o objeto sexo que contém as informações do sexo de uma pessoa. As possibilidades são: F (feminino) e M (masculino). Por padrão, o R interpreta essa variável como texto (character), no entanto, é possível transformá-la em fator por meio da função as.factor().\n\nsexo &lt;- c(\"F\", \"F\", \"M\", \"M\", \"F\")\nclass(sexo)\n\n[1] \"character\"\n\n# Transformando em fator\nclass(as.factor(sexo))\n\n[1] \"factor\"\n\nas.factor(sexo)\n\n[1] F F M M F\nLevels: F M\n\n\nObserva-se que a linha adicional Levels: F M indicam as categorias. Por padrão, o R ordena esses níveis em ordem alfabética. Para facilitar os cálculos e análises, o R interpreta os níveis categóricos como sendo números distintos, sendo assim, dentro do nosso exemplo F representaria o número 0 e M representaria o 1.\n\n\n3.6.6 Valores especiais\nValores como NA, NaN, Inf e NULL ocorrem frequentemente dentro do mundo da programação estatística no R. Em resumo:\n\nNA representa a Ausência de Informação. Suponha que o vetor idades que representa a idade de três pessoas. Uma situação que pode ocorrer é idades &lt;- c(10, NA, NA). Portanto, não é sabido a idade das pessoas 2 e 3.\nNaN representa indefinições matemáticas. Um exemplo típico é o valor \\(\\log{-1}\\), do qual \\(x = -1\\) não pertence aos possíveis valores de saída da função logarítmica, gerando um NaN (Not a number).\n\n\nlog(-1)\n\nWarning in log(-1): NaNs produzidos\n\n\n[1] NaN\n\n\n\nInf representa um número muito grande ou um limite matemático. Exemplos:\n\n\n# Número muito grande\n10^510\n\n[1] Inf\n\n# Limite matemático\n1/0\n\n[1] Inf\n\n\n\nNULL representa a ausência de um objeto. Muitas vezes define-se um objeto como nulo para dizer ao R que não desejamos atribuir valores a ele.\n\n\n\n3.6.7 Pedindo ajuda\nUma das coisas que intimidam novos programadores, independente da linguagem utilizada, é a ocorrência de erros. Neste sentido, o R pode ser um grande aliado, pois ele relata mensagens, erros e avisos sobre o código no console, como se fosse uma espécie de resposta e/ou comunicação. As situações são:\n\nError: em situações de erro legítimo aparecerá mensagens do tipo Error in ... e tentará explicar o que há de errado. Nestas situações o código, geralmente, não é executado. Por exemplo: Error in ggplot(...) : could not find function \"ggplot\".\nWarning: em situações de avisos, o R exibirá uma mensagem do tipo Warning: ... e tentará explicar o motivo do aviso. Geralmente, o código será executado, mas com algumas ressalvas. Por exemplo: Warning: Removed 2 rows containing missing values (geom_point).\nMessage: quando o texto exibido não se enquadra nas duas opções anteriores, dizemos que é apenas uma mensagem. Pense, nessa situação, que tudo está acontecendo como o esperado e está tudo bem.\n\nQuando surgir qualquer uma dessas saídas, não estaremos perdidos, pois o R oferece mecanismos para encontrarmos respostas. Afinal, nem todo mundo decorou todas as funções ou argumentos. Os principais mecanismos são:\n\n?função ou help(função) para consultar a documentação oficial.\n??termo e help.search(\"termo\") para buscas por palavras-chave.\n\nAlém disso, o RStudio oferece alguns Cheatsheets (resumo de códigos) que podem ajudar com determinados pacotes. E, por fim, existem grandes comunidade online, tais como: Stack Overflow e RStudio Community dos quais também podem serem úteis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "02-fundamentos.html#footnotes",
    "href": "02-fundamentos.html#footnotes",
    "title": "3  Fundamentos de R",
    "section": "",
    "text": "Existem outras IDEs que podem ser utilizadas no lugar do RStudio, como o Visual Studio Code. No entanto, focaremos nosso estudo utilizando o RStudio.↩︎\nUm outro repositório conhecido na comunidade científica para pacotes com o intuítuo de modelagem na biologia, em especial na genética, é o Bioconductor.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "03-tidyverse.html",
    "href": "03-tidyverse.html",
    "title": "4  Tidyverse",
    "section": "",
    "text": "4.1 Manipulação de dados com o pacote dplyr\nO tidyverse (WICKHAM ET AL., 2019) é um ecossistema de pacotes R que reúne as tarefas essenciais de qualquer fluxo de trabalho em ciência de dados: importação, organização, manipulação, visualização e programação. Seu principal objetivo é criar uma sintaxe consistente e legível, facilitando a comunicação entre quem escreve o código e quem o executa. Note-se que, embora o tidyverse cubra grande parte do fluxo de trabalho, ele não inclui ferramentas específicas de modelagem estatística.\nPara facilitar essa integração, o tidyverse utiliza intensamente do operador pipe1 (%&gt;%) , que passa o resultado de uma etapa diretamente para a próxima, evitando aninhamentos confusos. Ao carregar o pacote, diversos módulos são automaticamente disponibilizados:\nEntre os principais estão:\nComo dito, muitos pacotes definem funções com nomes idênticos, sendo costatumum que o console exiba nomes como:\nUm pilar do tidyverse é a adoção do princípio tidy (WICKHAM, 2014), em que:\nNesse contexto, a entidade observacional é o conceito central que define o que uma linha representa. Pode ser um paciente em um estudo clínico, um país em dados econômicos ou, como nos exemplos a seguir:\nA estrutura de dados que implementa essa filosofia no tidyverse é o tibble. Ele é a versão moderna do data.frame, projetado para ser mais prático e informativo, exibindo resumos concisos dos dados e fornecendo diagnósticos mais úteis.\nUma vez apresentada a filosofia e a estrutura de dados do tidyverse, o foco se volta para a aplicação prática. A seguir, a concentração do material residirá nos dois pacotes centrais do tidyverse: o dplyr, para manipulação de dados, e o ggplot2, para a criação de gráficos.\nO dplyr é um pacote do tidyverse que fornece um conjunto de ferramentas robustas e intuitivas para manipulação de dados. Os comandos oferecidos soam um tanto quanto intuitivos, correspondendo ações comuns na área de análise de dados. Para explorar as principais funções será utilizado o dataset penguins, focando em processos de filtragem, organização, transformação e resumos dos dados, permitindo responder a perguntas básicas sobre a biologia e ecologia dos pinguins.\nConhecendo os pinguins 🐧\nOs dados palmerpenguins contêm medições de tamanho de três espécies de pinguins observadas em três ilhas no arquipélago Palmer, na Antártida.\nEsses dados foram coletados entre 2007 e 2009 pela Dra. Kristen Gorman com o Programa de Pesquisa Ecológica de Longo Prazo da Estação Palmer , parte da Rede de Pesquisa Ecológica de Longo Prazo dos EUA . Os dados foram importados diretamente do Portal de Dados da Iniciativa de Dados Ambientais (EDI) e estão disponíveis para uso sob licença CC0 (“Sem Direitos Reservados”), de acordo com a Política de Dados da Estação Palmer.\nO primeiro passo a ser feito é instalar a biblioteca palmerpenguins e, em seguida, carregá-la no ambiente de trabalho, para que possamos realizar uma inspeção inicial na estrutura dos dados.\ninstall.packages(\"palmerpenguins\") # Realizar apenas uma única vez\nlibrary(palmerpenguins)\nPara carregarmos os dados sobre pinguins no ambiente de trabalho, podemos utilizar a função data():\ndata(\"penguins\", package = \"palmerpenguins\")\nPodemos observar que no painel Environment do RStudio, aparece o objeto penguins, isso significa que o conjunto de dados está carregado no ambiente de trabalho e podemos dar início nas inspeções. O primeiro comando que será visto é o glimpse(). Ele exibe, de maneira prática e rápida, a estrutura do dataset como: dimensão (número de linhas e colunas), o nome de cada coluna, o tipo de dado de cada coluna e as primeiras observações.\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\nA saída deste comando revela que existem 344 observações e 8 variáveis, sendo elas species, island, bill_length_mm, flipper_length_mm, body_mass_g, sex e year, com seus respectivos tipos, como factor para species e numeric para bill_length_mm. Além disso, é possível observar dados ausentes em algumas variáveis, representados por NA. Em geral, nos datasets disponíveis em pacotes R, é possível utilizar o comando help(penguins) para buscar informações sobre o conjunto de dados que será trabalhado.\nExecutando o comando de ajuda, são obtidas as seguintes informações sobre as variáveis:\nAdicionalmente, também é informado que os dados foram originalmente publicados no estudo de Gorman et al. (2014) e que essa pesquisa fez parte do programa Palmer Station Long-Term Ecological Research (LTER). Isso significa que o conjunto de dados que está sendo utilizado possui uma origem científica real, ligada a questões sobre como o ambiente e as diferenças entre sexos afetam a vida dessas aves.\nA segunda função que será vista é o select(). Frequentemente, um conjunto de dados contém mais informações do que o necessário para uma análise específica. Com isso em mente, a função select() permite-nos selecionar colunas de interesse. Em geral, os argumentos são os nomes das colunas.\npenguins %&gt;% \n  select(species, island, sex)\n\n# A tibble: 344 × 3\n   species island    sex   \n   &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt; \n 1 Adelie  Torgersen male  \n 2 Adelie  Torgersen female\n 3 Adelie  Torgersen female\n 4 Adelie  Torgersen &lt;NA&gt;  \n 5 Adelie  Torgersen female\n 6 Adelie  Torgersen male  \n 7 Adelie  Torgersen female\n 8 Adelie  Torgersen male  \n 9 Adelie  Torgersen &lt;NA&gt;  \n10 Adelie  Torgersen &lt;NA&gt;  \n# ℹ 334 more rows\nO dplyr também oferece “seletores auxiliares” que tornam a seleção mais poderosa e flexível. Por exemplo, caso desejarmos selecionar todas as medidas biométricas contidas no dataset que terminam com _mm, é possível usar a função-argumento ends_with() dentro de select():\npenguins %&gt;% \n  select(\n    body_mass_g, ends_with(\"_mm\")\n  )\n\n# A tibble: 344 × 4\n   body_mass_g bill_length_mm bill_depth_mm flipper_length_mm\n         &lt;int&gt;          &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n 1        3750           39.1          18.7               181\n 2        3800           39.5          17.4               186\n 3        3250           40.3          18                 195\n 4          NA           NA            NA                  NA\n 5        3450           36.7          19.3               193\n 6        3650           39.3          20.6               190\n 7        3625           38.9          17.8               181\n 8        4675           39.2          19.6               195\n 9        3475           34.1          18.1               193\n10        4250           42            20.2               190\n# ℹ 334 more rows\nOutros seletores úteis incluem starts_with() e contains(). Para remover colunas, utiliza-se o sinal de menos (-). Por exemplo, deseja-se remover as colunas ano e island:\npenguins %&gt;% \n  select(-year, -island)\n\n# A tibble: 344 × 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt; \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            NA            NA                  NA          NA &lt;NA&gt;  \n 5 Adelie            36.7          19.3               193        3450 female\n 6 Adelie            39.3          20.6               190        3650 male  \n 7 Adelie            38.9          17.8               181        3625 female\n 8 Adelie            39.2          19.6               195        4675 male  \n 9 Adelie            34.1          18.1               193        3475 &lt;NA&gt;  \n10 Adelie            42            20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\nAntes prosseguirmos para a próxima função, vale destacar que o conjunto de dados penguins é um objeto tibble dentro do R e, portanto, por mais que existam 344 observações, o tibble enxuga a visualização para somente 10, além de indicar quantas linhas ainda existem.\nA terceira função é o filter(). Enquanto select() trabalha nas colunas, o filter() trabalha nas linhas, permitindo-nos manter apenas as observações que satisfazem certas condições. É aqui que é possível responder perguntas investigadas com relação aos dados. Por exemplo, para encontrar todos os pinguins da espécie Adelie que vivem na ilha Torgersen:\npenguins %&gt;% \n  filter(\n      species == \"Adelie\", island == \"Torgersen\"\n    )\n\n# A tibble: 52 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 42 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nNeste exemplo, as condições separadas por vírgula são unidas por um “E” lógico. Também é possível utilizar o “OU” lógico para determinar pinguins mais pesados (acima de 6000g) ou com bicos muito longos (mais de 55mm) através do conectivo |:\npenguins %&gt;% \n  filter(\n    body_mass_g &gt; 6000 | bill_length_mm &gt; 55\n  )\n\n# A tibble: 6 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           49.2          15.2               221        6300\n2 Gentoo    Biscoe           59.6          17                 230        6050\n3 Gentoo    Biscoe           55.9          17                 228        5600\n4 Gentoo    Biscoe           55.1          16                 230        5850\n5 Chinstrap Dream            58            17.8               181        3700\n6 Chinstrap Dream            55.8          19.8               207        4000\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nO filter() também permite encontrar valores ausentes (NAs) em conjunto da função is.na(). Por exemplo, deseja-se verificar quais pinguins não tiveram seu sexo registrado:\npenguins %&gt;% \n  filter(is.na(sex))\n\n# A tibble: 11 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           NA            NA                  NA          NA\n 2 Adelie  Torgersen           34.1          18.1               193        3475\n 3 Adelie  Torgersen           42            20.2               190        4250\n 4 Adelie  Torgersen           37.8          17.1               186        3300\n 5 Adelie  Torgersen           37.8          17.3               180        3700\n 6 Adelie  Dream               37.5          18.9               179        2975\n 7 Gentoo  Biscoe              44.5          14.3               216        4100\n 8 Gentoo  Biscoe              46.2          14.4               214        4650\n 9 Gentoo  Biscoe              47.3          13.8               216        4725\n10 Gentoo  Biscoe              44.5          15.7               217        4875\n11 Gentoo  Biscoe              NA            NA                  NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nA interpretação do NA é relativa ao contexto dos dados. No caso das observações sobre os pinguins, os valores ausentes na variável sex permite identificar pinguins que não tiveram o sexo avaliado, tornando um provável erro frustrante de coleta de dados para um objeto de investigação. O pacote tidyr, também do tidyverse, oferece a função drop_na(), que remove quaisquer linhas que contenham NAs, permitindo a criação de um dataset auxiliar:\npenguins_completo &lt;- penguins %&gt;% \n  drop_na()\nA quarta função que será apresentada é arrange(), que permite reordenar as linhas do dataframe com base nos valores de uma ou mais colunas. Isso é útil para encontrar extremos ou simplesmente para organizar a saída de uma forma mais lógica. Para encontrar os pinguins mais leves, ordenamos pela massa corporal em ordem crescente (o padrão):\npenguins %&gt;% \n  arrange(body_mass_g)\n\n# A tibble: 344 × 8\n   species   island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;     &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Chinstrap Dream              46.9          16.6               192        2700\n 2 Adelie    Biscoe             36.5          16.6               181        2850\n 3 Adelie    Biscoe             36.4          17.1               184        2850\n 4 Adelie    Biscoe             34.5          18.1               187        2900\n 5 Adelie    Dream              33.1          16.1               178        2900\n 6 Adelie    Torgers…           38.6          17                 188        2900\n 7 Chinstrap Dream              43.2          16.6               187        2900\n 8 Adelie    Biscoe             37.9          18.6               193        2925\n 9 Adelie    Dream              37.5          18.9               179        2975\n10 Adelie    Dream              37            16.9               185        3000\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nPara ordenar os valores em ordem decrescente (do maior para o menor), utilizamos a função auxiliar desc(), desta maneira, encontramos os pinguins mais pesados:\npenguins %&gt;% \n  arrange(desc(body_mass_g))\n\n# A tibble: 344 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           49.2          15.2               221        6300\n 2 Gentoo  Biscoe           59.6          17                 230        6050\n 3 Gentoo  Biscoe           51.1          16.3               220        6000\n 4 Gentoo  Biscoe           48.8          16.2               222        6000\n 5 Gentoo  Biscoe           45.2          16.4               223        5950\n 6 Gentoo  Biscoe           49.8          15.9               229        5950\n 7 Gentoo  Biscoe           48.4          14.6               213        5850\n 8 Gentoo  Biscoe           49.3          15.7               217        5850\n 9 Gentoo  Biscoe           55.1          16                 230        5850\n10 Gentoo  Biscoe           49.5          16.2               229        5800\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nTambém é possível ordenar múltiplas colunas. Por exemplo, para encontrar o pinguim mais pesado dentro de cada espécie:\npenguins %&gt;% \n  arrange(\n    species, # Primeiro por espécie\n    desc(body_mass_g) # Depois por massa decrescente\n  )\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Biscoe              43.2          19                 197        4775\n 2 Adelie  Biscoe              41            20                 203        4725\n 3 Adelie  Torgersen           42.9          17.6               196        4700\n 4 Adelie  Torgersen           39.2          19.6               195        4675\n 5 Adelie  Dream               39.8          19.1               184        4650\n 6 Adelie  Dream               39.6          18.8               190        4600\n 7 Adelie  Biscoe              45.6          20.3               191        4600\n 8 Adelie  Torgersen           42.5          20.7               197        4500\n 9 Adelie  Dream               37.5          18.5               199        4475\n10 Adelie  Torgersen           41.8          19.4               198        4450\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nA quinta função e, com certeza, uma das mais funcionais é a mutate(). Ela permite criar novas colunas (variáveis) que são funções de colunas já existentes, sem modificar as originais. Por exemplo, suponha que desejamos mostrar somente as espécies e massas de pinguins em quilogramas (kg):\npenguins %&gt;% \n  mutate(body_mass_kg = body_mass_g/1000) %&gt;% \n  select(species, body_mass_kg)\n\n# A tibble: 344 × 2\n   species body_mass_kg\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 Adelie          3.75\n 2 Adelie          3.8 \n 3 Adelie          3.25\n 4 Adelie         NA   \n 5 Adelie          3.45\n 6 Adelie          3.65\n 7 Adelie          3.62\n 8 Adelie          4.68\n 9 Adelie          3.48\n10 Adelie          4.25\n# ℹ 334 more rows\nPodemos usar mutate() para criar categorias. A função case_when() é extremamente útil para criar classificações baseadas em condições lógicas., Suponha que desejamos criar uma categoria de tamanho baseada na massa corporal:\npenguins %&gt;% \n  mutate(\n    size_category = case_when(\n      body_mass_g &gt; 4750 ~ \"Grande\",\n      body_mass_g &lt; 3500 ~ \"Pequeno\",\n      TRUE ~ \"Médio\"\n    )\n  ) %&gt;% \n  select(\n    species, body_mass_g, size_category\n  )\n\n# A tibble: 344 × 3\n   species body_mass_g size_category\n   &lt;fct&gt;         &lt;int&gt; &lt;chr&gt;        \n 1 Adelie         3750 Médio        \n 2 Adelie         3800 Médio        \n 3 Adelie         3250 Pequeno      \n 4 Adelie           NA Médio        \n 5 Adelie         3450 Pequeno      \n 6 Adelie         3650 Médio        \n 7 Adelie         3625 Médio        \n 8 Adelie         4675 Médio        \n 9 Adelie         3475 Pequeno      \n10 Adelie         4250 Médio        \n# ℹ 334 more rows\nAs funções group_by() e summarise() formam uma dupla formidável para agrupar e resumir os dados, pertencendo ao coração da análise de dados. A função summarise() serve para calcular estatísticas resumidas (como média, total, mínimo etc.) e, quando usada em conjunto com group_by() permite gerar resumos por grupo.\nInicialmente, vamos utilizar o summarise() no dataset completo para obter estatísticas globais. Não obstante, é bom frisar a utilização do argumento na.rm = TRUE para instruir a remoção dos valores NA.\npenguins %&gt;% \n  summarise(\n    massa_media = mean(body_mass_g, na.rm = TRUE),\n    nadadeira_max = max(flipper_length_mm, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 2\n  massa_media nadadeira_max\n        &lt;dbl&gt;         &lt;int&gt;\n1       4202.           231\nNo entanto, essas métricas não fornecem informações com relação as espécies de pinguins. Para resolver isso e possibilitar que mais perguntas sejam respondidas, a função group_by() permite que o R faça operações em subconjuntos. Por exemplo, suponha que desejamos determinar qual é a massa corporal por espécie:\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(\n    massa_media_g = mean(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 2\n  species   massa_media_g\n  &lt;fct&gt;             &lt;dbl&gt;\n1 Adelie            3701.\n2 Chinstrap         3733.\n3 Gentoo            5076.\nPodemos fazer agrupamentos por múltiplas variáveis para investigações mais profundas. Por exemplo, considere que um pesquisador deseja explorar o dimorfismo sexual. Para isso, estatísticas por espécie e sexo serão calculadas.\n# A tibble: 6 × 6\n  species   sex    contagem massa_media_g massa_dp_g comp_bico_medio_mm\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;         &lt;dbl&gt;      &lt;dbl&gt;              &lt;dbl&gt;\n1 Adelie    female       73         3369.       269.               37.3\n2 Adelie    male         73         4043.       347.               40.4\n3 Chinstrap female       34         3527.       285.               46.6\n4 Chinstrap male         34         3939.       362.               51.1\n5 Gentoo    female       58         4680.       282.               45.6\n6 Gentoo    male         61         5485.       313.               49.5\nTabela 4.1: Estatísticas descritivas de características biométricas de pinguins, agrupadas por espécie e sexo.\n\n\n\n\n\n\nEspécies\nSexo\nContagem\nMassa média (g)\nMassa Desvio-padrão (g)\nComprimento médio do bico (mm)\n\n\n\n\nAdelie\nfemale\n73\n3368.84\n269.38\n37.26\n\n\nAdelie\nmale\n73\n4043.49\n346.81\n40.39\n\n\nChinstrap\nfemale\n34\n3527.21\n285.33\n46.57\n\n\nChinstrap\nmale\n34\n3938.97\n362.14\n51.09\n\n\nGentoo\nfemale\n58\n4679.74\n281.58\n45.56\n\n\nGentoo\nmale\n61\n5484.84\n313.16\n49.47\nVale reforçar que a Tabela 4.1 foi gerada usando o dplyr, com as funções auxiliares n() para realizar a contagem de observações em cada grupo e drop_na(sex) para remover as observações onde o sexo é desconhecido, permitindo avaliar dimorfismo sexual em todas as três espécies, especialmente na massa corporal. O grande potencial dessa tabela é obter respostas como:\nEsses resultados permitem tirar conclusões sobre algumas hipóteses biológicas.\nPor fim, a última função que será abordada é a recode(). Muitas vezes, os nomes das categorias nos conjuntos de dados não são ideais para a análise ou apresentação em gráficos. Podem ser longos demais, estarem em outro idioma ou simplesmente não serem claros. Para isso, a função recode() permite renomear valores de uma variável categórica de forma simples e direta. Por exemplo, suponha que desejamos traduzir os termos da variável sex da Tabela 4.1 para o português:\ntabela_resumo %&gt;% \n  mutate(\n    sex = recode(sex,\n                 \"female\" = \"Fêmea\",\n                 \"male\" = \"Macho\")\n  )\nTabela 4.2: Tradução da variável sexo da Tabela 4.1.\nAs principais funções do pacote dplyr que foram vistas estão resumidas e descritas na Tabela Tabela 4.3 e agora que aprendemos como manipular os dados com o dplyr, podemos avançar para a construção de gráficos com o pacote ggplot2.\nTabela 4.3: Descrição das principais funções do tidyverse.\n\n\n\n\n\n\nFunção\nDescrição\n\n\n\n\nglimpse()\nInspecionar conjuntos de dados.\n\n\nselect()\nSeleciona colunas pelo nome.\n\n\nfilter()\nFiltra linhas com base em seus valores.\n\n\narrange()\nReordena as linhas.\n\n\nmutate()\nCria novas colunas (variáveis).\n\n\ngroup_by()\nAgrupa os dados por uma ou mais variáveis.\n\n\nsummarise()\nReduz múltiplos valores a um único resumo.\n\n\nrecode()\nRenomeia categorias de variáveis.\n\n\nn()\nConta o número de observações.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "03-tidyverse.html#manipulação-de-dados-com-o-pacote-dplyr",
    "href": "03-tidyverse.html#manipulação-de-dados-com-o-pacote-dplyr",
    "title": "4  Tidyverse",
    "section": "",
    "text": "Obra de Horst et al. (2020).\n\n\n\n\n\n\n\n\n\n\nTerminologia das partes do corpo de um pinguim.\n\n\n\n\n\n\n\n\n\nspecies: um fator que denota a espécie do pinguim (Adélie, Chinstrap ou Gentoo).\nisland: um fator que denota ilhas no Arquipélago Palmer na Antártica (Biscoe, Dream ou Torgersen).\nbill_length_mm: um número que representa o comprimento do bico (em milímetros).\nbill_depth_mm: um número que representa a profundidade do bico (em milímetros).\nflipper_length_mm: um número que representa o comprimento da nadadeira (em milímetros).\nbody_mass_g: um número inteiro que representa a massa do animal (em gramas).\nsex: um fator que representa o sexo do animal (feminino ou masculino).\nyear: um número inteiro que denota o ano de estudo (2007, 2008 ou 2009).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOs pinguins Gentoo são, em média, os mais pesados.\nDentro de cada espécie, os machos são consistentemente mais pesados e têm bicos mais longo que as fêmeas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "03-tidyverse.html#visualização-de-dados-com-ggplot2",
    "href": "03-tidyverse.html#visualização-de-dados-com-ggplot2",
    "title": "4  Tidyverse",
    "section": "4.2 Visualização de Dados com ggplot2",
    "text": "4.2 Visualização de Dados com ggplot2\nSe o dplyr é a gramática da manipulação de dados, possuindo funções essenciais para esse trabalho, o ggplot2 (WICKHAM, 2016) é gramática dos gráficos, permitindo construir gráficos por meio de camadas e oferecendo um sistema robusto e flexível para visualização os dados. Nesta seção, continuaremos utilizando os dados dos pinguins para explorar alguns insights visuais, desde gráficos mais simples até os mais elaborados.\nTodo gráfico no ggplot2 é constituído por três camadas essenciais:\n\nDados (data): O dataframe que contém as informações a serem plotadas.\nMapeamento Estéticos (aes): A função aes() (de aesthetics) descreve como as variáveis do nosso dataframe são mapeadas para as propriedades visuais do gráfico. As estéticas mais comuns são x e y (os eixos), mas também incluem color (cor), shape (forma), size (tamanho) e alpha (transparência/opacidade).\nCamada (layers): O coração de qualquer gráfico são as camadas . Elas pegam os dados mapeados e os exibem em algo que os humanos possam entender como uma representação dos dados. Nessa parte que inserimos os objetos geométricos (geom): Os geoms definem como os dados são representados visualmente. Por exemplo, geom_point() cria um gráfico de dispersão, geom_bar() cria um gráfico de barras, geom_line() cria um gráfico de linhas, e assim por diante.\n\n\n\n\nNa imagem, temos todas as camadas que são utilizadas pelo ggplot2, seguindo a ordem debaixo para cima\n\n\nAlém das três camadas essenciais (dados, mapeamento estético e objetos geométricos), o ggplot2 permite adicionar outras camadas para refinar e personalizar seus gráficos:\n\nCamada da Escala (scales): Essa camada controla o mapeamento entre os valores dos dados e as propriedades visuais. Por exemplo, ela define a cor, o tamanho e a forma dos objetos, além de permitir a personalização dos eixos (como a definição de limites e rótulos).\nCamada de Subdivisão (facets): As facetas são uma maneira de criar múltiplos gráficos, dividindo seus dados em subgrupos com base em uma ou mais variáveis. Elas são ideais para explorar relações condicionais nos dados. facet_wrap() e facet_grid() são as funções mais comuns para essa finalidade.\nCamada do Sistema de Coordenadas (coord): Esta camada define como os dados são mapeados para a superfície do gráfico. A coordenada padrão é a Cartesiana, mas você pode usar outras, como coord_polar() para gráficos de pizza ou coord_flip() para inverter os eixos x e y.\nCamada do Tema (theme): O tema controla os elementos não relacionados aos dados, como as fontes, as cores de fundo, os rótulos dos eixos e as legendas. É o que permite dar uma aparência mais profissional e personalizada aos seus gráficos.\n\nAo combinar essas camadas de maneira lógica, o ggplot2 oferece um sistema flexível para a construção de gráficos, permitindo que você adicione complexidade gradualmente, mantendo o código organizado e legível.\n\n4.2.1 Estatística descritiva\nAntes de explorar as relações gráficas, é útil enfatizar e entender alguns conceitos essenciais da Estatística Descritiva como os tipos de variáveis, normas para tabelas e as definições de frequências.\n\nEm geral, pode-se dizer que existem duas categorias de variáveis dentro da estatística:\n\nVariáveis Qualitativas: Também chamadas por variáveis categóricas e como o próprio nome diz, expressam qualidade e indicam categoria ou classificação a qual o objeto pertence. Se existir uma ordem entre as possíveis categorias, a variável é dita qualitativa ordinal. Caso contrário, é dita ser qualitativa nominal.\nVariáveis Quantitativas: São variáveis que tomam valores numéricos e expressam quantidade. Podem ser especificadas por Variáveis Discretas, quando assumem valores dentro de um conjunto enumerável (quando é possível contá-las) ou por Variáveis Continuas, quando podem assumir infinitos valores de um intervalo não numerável2 (não é possível contar o número de valores dentro de um intervalo).\n\nAssim, para explorar e apresentar as informações contidas num conjunto de dados, precisamos resumir essas informações de forma que seja possível enxergá-las rapidamente e adquirir conhecimento sobre o assunto.\nO resumo pode ser feito por meio de tabelas, gráficos e cálculo de algumas quantidades representativas. O primeiro passo é identificar o tipo de cada variável para aplicarmos a técnica apropriada.\nNo entanto, antes de explorarmos a organização dos dados em tabelas e gráficos, são necessários conceitos sobre algumas métricas essenciais denominadas por medidas resumo. Elas oferecem uma forma numérica e concisa de descrever as principais características das variáveis que serão trabalhadas. Em geral, são divididas em duas categorias essenciais: as medidas de tendência central, que informam onde o “centro” dos dados se localiza (como a média, mediana e moda), e as medidas de dispersão, que quantificam o quão espalhados os dados estão (como a amplitude, o desvio padrão e a variância).\nA média aritmética é definida como sendo a soma de todos os valores dividida pelo número de observações ou indivíduos, ou seja, denotando-se as \\(n\\) observações de uma variável \\(X\\) por \\(x_1, x_2, \\dots, x_n\\) e a média por \\(\\bar{x}\\) temos: \\[\\bar{x} = \\frac{1}{n}\\sum_{i = 1}^{n} x_i\\] As principais propriedades da média são:\n\nÉ uma medidas simples e popular;\nÉ sensível aos valores e discrepantes ou extremos. Portanto, na presença destes, a média pode não ser uma representação de valores típicos;\nÉ o ponto de equilíbrio da distribuição;\nPara \\(k\\) constante e \\(X\\) variável, têm-se que a média de \\((X + k)\\) é \\((\\bar{x} + k)\\) e, também, a média de \\((kX)\\) é \\((k\\bar{x})\\).\nPara \\(X\\) e \\(Y\\) variáveis independentes, a média de \\((X\\pm Y)\\) é \\((\\bar{x} \\pm \\bar{y})\\).\n\nA mediana é o valor do meio de uma distribuição, ou seja, num histograma, é o valor que deixa exatamente 50% dos dados de cada lado. Para determinar o valor exato da mediana é necessário ordenar todos os valores, do menor para o maior. Se \\(n\\), o número de observações, é ímpar então a mediana é o valor que fica exatamente no centro; se \\(n\\) é par, então é a média dos dois valores centrais.\nAs principais propriedades da mediana são:\n\nNão é sensível a valores discrepantes e, portanto, é a mais apropriada para representar valores típicos quando a distribuição é assimétrica;\nNão apresenta as propriedades matemáticas convenientes que a média possui.\n\nQuando a distribuição é simétrica, média e mediana são iguais. No entanto, caso contrário, a média estará mais afastada do meio que a mediana no sentido de uma cauda mais longa.\nA moda é simplesmente o valor mais frequente da variável de estudo e para distribuições simétricas, média, mediana e moda possuem valores iguais.\nUma vez reconhecido o centro da distribuição, é necessário ter uma ideia do quanto os valores estão distantes deste centro. Quanto mais heterogêneo forem os dados, maior a dispersão e vice-versa. Dentre as métricas que dão essa ideia, destacam-se:\nA amplitude definida pela diferença entre o maior e o menor valor. Além disso, é sensível a valores extremos. O primeiro quartil (\\(q_1\\)) e terceiro quartil (\\(q_3\\)), que dividem, respectivamente, o conjunto de dados em 25% e 75%. É válido ressaltar que todo conjunto de dados apresentam 3 quartis, dividindo o conjunto ordenado em quatro partes iguais, além disso, o segundo quartil (\\(q_2\\)) é igual a mediana. Essas medidas são úteis na construção do gráfico de caixa (boxplot) que será visto em sequência.\nO desvio padrão (\\(s\\)) é a medida de dispersão mais popular e mede a dispersão de todos os valores em relação à média. Para calculá-lo, primeiramente calcula-se a variância, denotada por \\(s^2\\), que é definida por: \\[s^2 = \\mathbb{V}(X) = \\frac{1}{n-1}\\sum_{i = 1}^{n}(x_i - \\bar{x})^2 = \\frac{1}{n-1}\\left(\\sum_{i = 1}^{n}x_i^2 - \\frac{\\left(\\sum_{i = 1}^{n} x_i\\right)^2}{n}\\right)\\] a diferença \\((x_i - \\bar{x})\\) é chamada de desvio, representando o quanto o indivíduo \\(i\\) desviou da média geral. A variância representa a média dos quadrados dos desvios em relação à média. Além disso, observe que a unidade de medida da variância é a unidade da variável \\(x\\) ao quadrado, dificultando sua interpretação e, para lidar com isso, utiliza-se o desvio-padrão, visto que é seu valor está na mesma escala de medida das observações, em que valores altos indica que os dados estão bastante dispersos e valores baixos, os indivíduos estão próximos da média, mostrando uma homogeneidade nos dados. As principais propriedades da variância (ou do desvio padrão) são:\n\nPara \\(k\\) constante, \\(\\mathbb{V}(k) = 0\\), \\(\\mathbb{V}(k + X) = \\mathbb{V}(X)\\), \\(\\mathbb{V}(kX) = k^2\\mathbb{V}(X)\\);\nPara \\(X\\) e \\(Y\\) variáveis independentes, \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y)\\);\nÉ sensível aos valores discrepantes e, portanto, só deve ser usada quando a distribuição é simétrica ou aproximadamente simétrica.\n\nPor fim, existe o coeficiente de varição (\\(\\text{cv}\\)), que é uma medida de dispersão em termos de porcentagem da média: \\[\\text{cv} = \\frac{s}{\\bar{x}}\\times 100,\\] em que não há unidade de medida e, portanto, serve como métrica de comparação na variação de variáveis diferentes.\nDentro do R, a função summary() é a chave mestre que calcula quase todas as métricas que foram vistas. Para exemplificar, selecionaremos apenas a variável bill_length do conjunto de dados penguins (Tabela 4.4).\n\npenguins %&gt;% \n  select(bill_length_mm) %&gt;% \n  summary()\n\n\n\n\n\nTabela 4.4: Saída da função summary()\n\n\n\n\n\n\nVariável\nMin\n1º Quad.\nMediana\nMédia\n3º Quad.\nMax\nNAs\n\n\n\n\nbill_length_mm\n32.1\n39.225\n44.45\n43.92193\n48.5\n59.6\n2\n\n\n\n\n\n\n\n\nEnquanto as medidas resumo nos fornecem valores pontuais para compreensão do centro e a dispersão, as tabelas oferecem uma visão panorâmica da distribuição dos dados. Organizar as informações de forma tabular é o primeiro para visualizar as frequências de cada categoria ou intervalo, complementando a análise numérica anterior.\nAs normas gerais para construção de uma tabela envolvem:\n\nDevem ser auto-explicativas.\nDevem conter um título, que precisa ser simples e claro, indicando informações sobre os dados (do que, onde e quando foram coletados – se forem relevantes).\n\nAlém das normas gerais, existem duas convenções importantes a serem seguidas com relação ao título de tabelas e gráficos:\n\nEm tabelas os títulos vem primeiro, em cima da tabela.\nEm gráficos os títulos vem por último, embaixo do gráfico.\n\nSe necessário, notas e fontes vêm embaixo, em ambos os casos. Uma tabela começa e termina com um traço horizontal e traços na vertical devem ser evitados, conforme visto na Tabela 4.1 por exemplo.\nUma forma adequada para resumir informações sobre uma variável numa tabela é através da construção de uma tabela de frequências, que informa quais valores ou categorias a variável pode tomar, com suas respectivas frequências. Quando a variável é qualitativa, as frequências vão revelar se temos categorias mais comuns (típicas) e categorias raras ou se a distribuição é uniforme/homogênea. Já quando a variável é quantitativa, as frequências revelarão os valores típicos e/ou a distribuição dos valores é simétricas ou assimétrica.\nExistem alguns tipos de frequência que podem ser utilizados para resumir as informações, dentre eles:\n\nFrequência absoluta ou simplesmente frequência (\\(f\\)): é a contagem do número de vezes que um valor ou categoria aparece.\nFrequência relativa (\\(\\text{fr} = f/n\\)): quando esse valor é multiplicado por \\(100\\), informa a porcentagem do aparecimento de uma determinada categoria sobre o número total de contagem.\nFrequência acumulada (\\(\\text{fa}\\)): é a frequência acumulada até um valor específico.\nFrequência acumulada relativa (\\(\\text{far} = \\text{fa}/n\\)): quando esse valor é multiplicado por \\(100\\), informa a porcentagem acumulada do aparecimento de uma determinada categoria sobre o número total de contagem.\n\nA Tabela 4.5 contém as informações sobre as frequências de cada espécie de pinguim existente no conjunto de dados penguins. As informações básicas que podem ser extraídas é que entre as espécies dentro do estudo sobre pinguins 44.2% são Adelie, 36% são Gentoo e 19.8% são Chinstrap.\n\n\n\n\nTabela 4.5: Distribuição de frequências para as espécies de Pinguins.\n\n\n\n\n\n\nEspécies\nFrequência\nFrequência absoluta\nPorcentagem\n\n\n\n\nAdelie\n152\n0.442\n44.2\\%\n\n\nGentoo\n124\n0.360\n36\\%\n\n\nChinstrap\n68\n0.198\n19.8\\%\n\n\nTotal\n344\n1.000\n100\\%\n\n\n\n\n\n\n\n\nQuando a variável é quantitativa e assume muitos valores distintos, para resumir e capturar o padrão da distribuição, esses valores devem ser agrupados em intervalos. A quantidade de intervalos é arbitrário, no entanto, não pode ser nem muito baixo e nem muito alto. O próximo passo é especificar os intervalos, contando quantos valores aparecem dentro de cada um deles.\nPara exemplificar, utilizaremos a variável body_mass_g de nosso conjunto de dados sobre os pinguins. Em geral, segue-se os passos:\n\nCalcular a amplitude (\\(A\\)) dos dados.\n\n\npenguins %&gt;% \n  summarise(\n    maior = max(body_mass_g, na.rm = TRUE),\n    menor = min(body_mass_g, na.rm = TRUE),\n    amplitude = max(body_mass_g, na.rm = TRUE) - min(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 3\n  maior menor amplitude\n  &lt;int&gt; &lt;int&gt;     &lt;int&gt;\n1  6300  2700      3600\n\n# Ou ainda\nA &lt;- penguins %&gt;% \n  summarise(\n    amplitude = diff(range(body_mass_g, na.rm = TRUE))\n  )\n\n\nEncontrar o comprimento aproximado de cada intervalo, dividindo \\(A\\) pelo número de intervalos desejados.\n\n\nA/6\n\n  amplitude\n1       600\n\n\nA partir da Tabela 4.6 e pela coluna das frequências relativas, observa-se que a distribuição do peso é assimétrica. Em breve, isso será observado graficamente.\n\n\n\n\nTabela 4.6: Distribuição de frequências para a massa corporal (g) dos pinguins.\n\n\n\n\n\n\nMassa corporal (g)\nFrequência\nf.r. (%)\nf.a.r. (%)\n\n\n\n\n2700 ⊢ 3300\n34\n9.94%\n9.94%\n\n\n3300 ⊢ 3900\n110\n32.16%\n42.11%\n\n\n3900 ⊢ 4500\n80\n23.39%\n65.5%\n\n\n4500 ⊢ 5100\n60\n17.54%\n83.04%\n\n\n5100 ⊢ 5700\n41\n11.99%\n95.03%\n\n\n5700 ⊢ 6300\n17\n4.97%\n100%\n\n\n\n\n\n\n\n\n\n\n4.2.2 Tipos de gráficos\nAs distribuições de frequências podem ser representadas em gráficos, que facilitam a interpretação visual do comportamento dos dados. Os gráficos mais comuns, segundo o tipo de variável, são:\n\nBarras ou colunas: apropriado para variáveis qualitativas e quantitativas discretas.\nSetores: qualitativas nominais com poucas categorias.\nHistograma: qualitativas contínuas.\nBox-plot: quantitativas.\nDiagrama de dispersão: relaciona duas quantitativas.\nGráfico de linhas: evolução de quantitativa ao longo do tempo ou espaço.\n\nCom esse conhecimento em mente podemos prosseguir para as construções dos gráficos.\nO pacote ggplot2 funciona com construção de “camadas” (layers). O comando ggplot() inicia um gráfico vazio.\n\nggplot()\n\n\n\n\n\n\n\n\nA partir deste gráfico vazio, podemos adicionar camadas de pontos, linhas, barras, caixas, entre outros. Dê uma olhada no manual de referência. Outros como tidyverse, ou Curso de R podem ajudar bastante! Explore o máximo.\n\n4.2.2.1 Adicionando layers\nDe maneira geral, a sintaxe que vamos usar é geom_yyy(data = dados, aes(x = x, y = y)), sendo que iremos substituir yyy por “line” para linhas, “point” para pontos e assim por diante.\nPara praticar um pouco, podemos fazer uma visualização da relação entre a massa corporal (eixo \\(X\\)) e o comprimento da nadadeira (eixo \\(Y\\)):\n\nggplot(penguins_completo) +\n  geom_point(aes(x = body_mass_g, y = flipper_length_mm))\n\n\n\n\n\n\n\n\nSe quisermos que os pontos tenham uma cor em particular, adicionamos a cor dentro de geom_point().\n\nggplot(data = penguins_completo) +\n  geom_point(aes(x = body_mass_g, y = flipper_length_mm), color = \"blue\")\n\n\n\n\n\n\n\n\nOu ainda, podemos utilizar a lógica do tidyverse e aplicar um pipe para criar nosso gráfico.\n\npenguins_completo %&gt;% \n  ggplot() +\n  geom_point(aes(x = body_mass_g, y = flipper_length_mm), color = \"blue\")\n\n\n\n\n\n\n\n\nA cor de cada ponto também pode ser definida por uma variável (como a espécie), mas precisará ser inserida dentro de aes().\n\npenguins_completo %&gt;% \n  ggplot() +\n  geom_point(aes(x = body_mass_g, y = flipper_length_mm, color = species))\n\n\n\n\n\n\n\n\nCom a lógica fundamental do ggplot2 em mente, vamos agora explorar algumas visualizações comuns para analisar nossos dados.\n\n\n4.2.2.2 Visualizando uma única variável\nPara visualizar a distribuição de uma variável contínua como a massa corporal, utiliza-se o histograma com a função geom_histogram(). Como já foi visto, a escolha do número de colunas é arbitrário e pode afetar significativamente a aparência e a interpretação do gráfico.\n\npenguins %&gt;% \n  ggplot(mapping = aes(x = body_mass_g))+\n    geom_histogram()\n\n\n\n\nDistribuição da massa corporal (g) dos pinguins.\n\n\n\n\nMas esse gráfico não fornece informações úteis, pois contém muitas colunas, além disso não está esteticamente apresentável. Vamos aprimorá-lo.\n\npenguins %&gt;% \n  ggplot(mapping = aes(x = body_mass_g))+\n    geom_histogram(color = \"white\", fill = \"steelblue\",\n                   breaks = seq(2700, 6300, by = 600), \n                   closed = \"left\")+\n    scale_x_continuous(\n      breaks = seq(2700, 6300, by = 600),\n      labels = seq(2700, 6300, by = 600),\n      limits = c(2700, 6300)\n    )+\n    labs(\n      x = \"Massa corporal (g)\",\n      y = \"Contagem\"\n    )+\n    ggthemes::theme_clean()\n\n\n\n\nDistribuição da massa corporal (g) dos pinguins.\n\n\n\n\nObserve que a biblioteca ggthemes foi utilizada para melhorar o aspecto estético do gráfico, fornecendo temas adicionais. Portanto, é recomendável instalá-la e carregá-la no espaço de trabalho.\n\n# install.packages(\"ggthemes\")\nlibrary(ggthemes)\n\nPara variáveis categóricas, como species, usamos o geom_bar() para criar um gráfico de barras que mostra a contagem de observações em cada categoria.\n\npenguins %&gt;% \n  ggplot(mapping = aes(x = species, fill = species))+\n    geom_bar()+\n    labs(\n      x = \"Espécies\",\n      y = \"Número de Indivíduos\"\n    )+\n    labs(\n        x = \"Espécies\",\n        y = \"Contagem\",\n        fill = \"Espécies\"\n      )+\n    theme_clean()+\n    theme(legend.position = \"bottom\")\n\n\n\n\nDistribuição de Pinguins por Espécie.\n\n\n\n\n\n\n4.2.2.3 Relações entre variáveis\nO gráfico de dispersão é a ferramenta clássica para explorar relações entre duas variáveis numéricas. Investigaremos a relação existente entre o comprimento da nadadeira e a massa corporal. A hipótese é que pinguins com nadadeiras maiores também serão mais pesados, uma relação positiva e intuitiva que serve como um excelente parâmetro de partida. Como vimos anteriormente, o gráfico dessa relação fica da seguinte forma:\n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g))+\n    geom_point()+\n    labs(\n      x = \"Comprimento da Nadadeira (mm)\",\n      y = \"Mass corporal (g)\"\n    )+\n  theme_clean()\n\n\n\n\n\n\n\nFigura 4.1: Relação entre o tamanho da nadadeira (mm) e o peso corporal (g) dos pinguins.\n\n\n\n\n\nA Figura 4.1 informa uma clara tendência positiva entre a nadadeira e o peso corporal dos pinguins. Mas será que esse tendência é a mesma para todas as espécies? Para responder essa pergunta, através da função aes(), é possível adicionar estéticas adicionais como shape, color ou size para distinguir as espécies no gráfico. O argumento a ser utilizado dependerá onde a imagem será utilizada. Por exemplo, em uma revista científica, que solicita gráficos em preto e branco, é aconselhável utilizar shape ou size.\n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species))+\n    geom_point()+\n    labs(\n      x = \"Comprimento da Nadadeira (mm)\",\n      y = \"Massa corporal (g)\",\n      color = \"Espécies\"\n    )+\n    theme_clean()+\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigura 4.2: Relação entre o tamanho da nadadeira (mm) e o peso corporal (g) por espécie dos pinguins.\n\n\n\n\n\nA Figura 4.2 revela detalhes mais pertinentes, mostrando que a relação entre massa corporal e comprimento da nadadeira mantêm-se positiva (nível de grupo).\nPara comparar a distribuição de uma variável numérica entre diferentes categorias, o boxplot3 (geom_boxplot()) é uma excelente ferramenta. Para isso, vamos comparar a distribuição da massa corporal entre as três espécies.\n\npenguins %&gt;% \n  ggplot(aes(x = species, y = body_mass_g, fill = species))+\n    geom_boxplot()+\n    labs(\n      x = \"Espécies\",\n      y = \"Massa corporal (g)\",\n      fill = \"Espécies\"\n    )+\n    theme_clean()+\n    theme(legend.position = \"none\")\n\n\n\n\nBoxplot para a massa corporal (g) por espécies de pinguins.\n\n\n\n\nUma alternativa ao geom_boxplot() é o geom_violin(), que traz um detalhamento sobre os dados de uma maneira mais simples. Adicionalmente, podemos utilizar o geom_jitter() para evitar a sobreposição dos dados, enriquecendo o visual do gráfico.\n\npenguins %&gt;% \n  ggplot(aes(x = species, y = body_mass_g, fill = species))+\n    geom_violin(alpha = 0.5)+\n    geom_jitter(width = 0.1, alpha = 0.5)+\n    labs(\n      x = \"Espécie\",\n      y = \"Massa corporal (g)\"\n    )+\n    theme_clean()+\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Técnicas avançadas de visualização e comunicação\nCom a base da construção de gráficos vista anteriormente, é possível explorar técnicas para criar gráficos mais ricos e informativos, complementando informações descobertas de forma eficaz.\n\n\n4.2.4 Sub-gráficos com facet_wrap()\nAs facetas permitem criar uma matriz de gráficos, dividindo os dados com uma base em uma ou mais variáveis categóricas. Isso é extremamente útil para comparações. Para exemplificar, vamos utilizar o gráfico de dispersão e segmentá-lo para a variável sex.\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  mutate(\n  sex = recode(sex,\n         \"female\" = \"Fêmea\",\n         \"male\" = \"Macho\")\n  ) %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species))+\n    geom_point()+\n    facet_wrap(~ sex)+\n    labs(\n      x = \"Comprimento da nadadeira (mm)\",\n      y = \"Massa corporal (g)\",\n      color = \"Espécies\"\n    )+\n    theme_clean()+\n    theme(legend.position = \"bottom\")\n\n\n\n\nDistribuição de massa corporal (g) por espécie.\n\n\n\n\nNeste gráfico, fica evidente que os pinguins fêmeas possuem menos massa corporal que os machos e, quanto as espécies, Gentoo é que concentra a maior massa. Contudo, pode ser do interesse do pesquisador além de verificar a massa corporal por sexo, também incluir a variável island.\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  mutate(\n  sex = recode(sex,\n         \"female\" = \"Fêmea\",\n         \"male\" = \"Macho\")\n  ) %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species))+\n    geom_point()+\n    facet_wrap(island ~ sex)+\n    labs(\n      x = \"Comprimento da nadadeira (mm)\",\n      y = \"Massa corporal (g)\",\n      color = \"Espécies\"\n    )+\n    theme_clean()+\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigura 4.3: Distribuição de massa corporal (g) nas ilhas por espécie.\n\n\n\n\n\nA partir da Figura 4.3 é possível reparar que nem todas as espécies estão presentes nas três ilhas simultaneamente. Além disso, a ilha de Biscoe é a que apresenta o maior percentual de massa corporal dos pinguins, isto é, a espécie Gentoo é a predominante.\n\n\n\n\nGORMAN, Kristen B. et al. Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis). PLOS ONE, v. 9, n. 3, p. e90081, 2014.\n\n\nHORST, Allison Marie et al. palmerpenguins: Palmer Archipelago (Antarctica) penguin data. [S.l.: S.n.].\n\n\nWICKHAM, Hadley. Tidy Data. Journal of Statistical Software, v. 59, p. 1–23, set. 2014.\n\n\nWICKHAM, Hadley. Ggplot2. Cham: Springer International Publishing, 2016.\n\n\nWICKHAM, Hadley et al. Welcome to the Tidyverse. Journal of Open Source Software, v. 4, n. 43, p. 1686, nov. 2019.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "03-tidyverse.html#footnotes",
    "href": "03-tidyverse.html#footnotes",
    "title": "4  Tidyverse",
    "section": "",
    "text": "A partir da versão 4.1 do R, existe também o operador pipe nativo |&gt;. No entanto, nesta apostila manteremos o uso de %&gt;%, amplamente adotado no contexto do tidyverse.↩︎\nTente contar os números do conjunto \\(A = \\{1,2,3,4\\}\\) e, também, de \\(B = [1,4]\\). Observe que no conjunto \\(A\\) há 4 elementos, enquanto em \\(B\\) há infinitos valores de 1 a 4.↩︎\nTambém chamado por gráfico de caixas.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "GORMAN, Kristen B. et al. Ecological\nSexual Dimorphism and Environmental\nVariability within a Community of Antarctic\nPenguins (Genus Pygoscelis). PLOS\nONE, v. 9, n. 3, p. e90081, 2014.\n\n\nWICKHAM, Hadley. Tidy\nData. Journal of Statistical Software,\nv. 59, p. 1–23, set. 2014.\n\n\nWICKHAM, Hadley. Ggplot2.\nCham: Springer International Publishing, 2016.\n\n\nWICKHAM, Hadley et al. Welcome to the\nTidyverse. Journal of Open Source\nSoftware, v. 4, n. 43, p. 1686, nov. 2019.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minicurso: Ciência de Dados com R – Uma Introdução Prática",
    "section": "",
    "text": "1 Prefácio\nO universo da Ciência de Dados se expande rapidamente, e com ele, a necessidade de ferramentas acessíveis e eficazes para análise e modelagem. O R se destaca nesse cenário por sua comunidade ativa e um ecossistema de pacotes em constante evolução, como o tidyverse.\nEste minicurso foi elaborado para ser uma introdução prática à ciência de dados com R. Em vez de nos aprofundarmos em teorias complexas, focamos na aplicação, guiando você por um fluxo de trabalho completo, desde a manipulação e visualização de dados até a construção e avaliação de modelos de machine learning.\nNosso percurso inclui:\n\nFundamentos do R: Uma breve revisão dos conceitos essenciais da linguagem.\nTidyverse: A filosofia por trás de um dos ecossistemas mais populares do R, que simplifica a organização, transformação e visualização de dados com uma sintaxe limpa e intuitiva.\nModelagem de Machine Learning: Uma introdução prática aos modelos de classificação, usando dados sintéticos e reais para ilustrar como eles funcionam e para que servem.\n\nAo final deste material, você terá as bases necessárias para iniciar seus próprios projetos de análise de dados, entendendo não apenas como o código funciona, mas também o porquê de cada passo. Esperamos que este possa ser o ponto de partida para sua jornada na área de ciência de dados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prefácio</span>"
    ]
  }
]